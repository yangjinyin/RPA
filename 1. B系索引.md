

# 一. B tree索引

  B系索引在高并发中主要解决两个核心问题

1. 读正确：比如正在读/写一个结点的数据，恰好这时有另外一个并发写线程，在这个结点上插入新的数据，结点内的数据发生移动，导致我读到了错误的数据或把结点数据写坏了
  2. 读/写失效：刚从父结点读到了子结点的指针，这时有一个并发写线程把子结点写满了，子结点发生了 split，一部分数据挪到了子结点右边的新结点上去了。我要读的数据就在这些被挪走的数据之中，接下来我拿着子结点的指针去访问子结点，就找不到要读的数据了



最简单的方案就是在读写B-tree时，直接加一把整个B-TREE级别的大锁。search的时候加读锁，insert/delete的时候加写锁。问题是这个锁的粒度太大，导致性能很差。接下来就是几种优化方案



### 1.1  Latch crabbing(1970)：

将锁的粒度降低到B-tree节点级别，对节点加读写锁。具体如下：

   i： Search时自上而下对节点加锁，获得子节点后立即释放父节点的锁。
   ii: insert时自上而下对节点加写锁，获得子节点的锁后。判断子节点是否safe（无须split/merge），如是，则立刻释放所有祖先节点的写锁。如果否，则持有锁直至分裂完成。
   iii:  delete时如果是非safe场景，需要merge时，则先向上递归获取各个节点的sibling的写锁，当同层merge完成后再释放所有锁。

基础的 Latch Crabbing 本质是悲观锁，Insert, Remove 都要对根节点加写锁。在此基础上改进成乐观锁



#### 1.2  optimistic latching  (1971)

​     i: Search 操作跟 latch crabbing 方案一样。

​     ii: Insert/delete 自上而下加结点的读锁。到达叶子结点后，对叶子结点加写锁。判断叶子结点是否 safe。如果不 safe，放锁，然后用悲观的 latch crabbing 方案重试。 

 这种场景下性能提升很大，但是还是有锁，我们希望能降低锁，甚至做到lock-less。那么blink-tree 在1981被提出来了。也成为pg实现索引的基础。

### 1.3 blink-tree (1981)

blink-tree核心设计有两点
   a：Right sibling 指针，指向结点的右邻居结点。
   b：High key，存储节点以及所有子节点中最大的key

![img](https://pic4.zhimg.com/v2-3a17f45e2694e298a97ae4d15542bf41_r.jpg)

i：Search 时候不加锁。当下降到子节点后，如果子节点上的high key 小于我要搜索的key。说明子节点发生了split，节点被移到右兄弟了。那么则通过right-sibling指针从左往右查找，直到找到对应的key。找到后加读锁+pin。防止被其他进程修改

ii：Insert/delete 操作：下降过程中不加锁，到达子节点后，对其子节点加锁。如果不safe （split), 则找到父节点并加锁，同时把父节点的右兄弟也加锁。当然还存在一种场景，父节点中该叶子节点的指针已经不存在了（父节点的high key 小于当前值），说明父节点的别的子节点触发了父节点的split，此时，则需要沿着父节点同层向右找到新的父节点 。（新的父节点的high key > 当前子节点的high key）。

​       如果父节点也满了，则依次递归往上加锁操作。

​       可以发现blink-tree加锁是自低往上的，且是乐观机制。最多只会加3个节点的锁。



### 1.4 OLFIT on B+-Trees（Optimistic Latch Free Index Access Protocol）(2001)

![img](https://pic3.zhimg.com/v2-5a2c0d7eefa9e47b48634e04a63e9dc2_1440w.jpg)

这个读无锁的算法方案，是在tree的基础上，每个节点记录一个版本号，对于节点写操作时则会增加版本号。读之前记录一下版本号，读取成功后再校验一下版本号，如果便了，则需要重新读取一遍

1. Search 操作不加锁，只校验版本号（这种方式其实也相当于一种结点的乐观锁）。
2. Insert/delete 操作与 B+-tree 的加锁方式一样。



### 1.5 bw-tree的读写无锁方案  （2013）

 bw-tree是微软提出来的一种读写无锁方案，并在sql-server中实现

​	![img](https://pic4.zhimg.com/v2-1fb984b9262865278cf3926d1e6fd9ad_r.jpg)

   Bw-tree 中每个B-tree 结点挂一个无锁链表，对 B-tree 结点的增量更新（插入和删除，上图中表示为 Δ）不会 in-place 地改 B-tree 结点的数据，而是把更新操作记录下来插入到到结点的无锁链表的头部，无锁链表的尾部结点指向它对应的 B-tree 结点。我们拿到无锁链表的任意一个结点，将从这个结点开始到链表尾部的更新都 apply 到 B-tree 结点上，就能得到这个 B-tree 结点的一个特定的一致性快照版本，也就是说 Bw-tree 实现了结点的多版本机制。 Bw-tree 中会有一个单独的数据结构 Mapping Table 来存储每个 B-tree 结点 id 到它的无锁链表的头部（换句话说，结点的最新版本）的映射。



# 二. LSM tree

LSM-Tree（Log-Structured Merge-Tree）是一种为高吞吐量读写操作优化的数据结构，特别适用于写入密集型的应用场景。它由Patrick O'Neil等人开发，旨在提供一种低成本的索引方法，以处理大量记录插入和删除的操作。以下是对LSM-Tree的简介和关键技术要点的总结

### 2.1 设计

1. LSMTree是个多"子树"的"森林"。分为level0，level1，...n颗子树，其中level0在内存中，其他在磁盘中

2. level0在内存中采用排序树（avl树/红黑树），跳表等有序的数据结构，其方便顺序写入磁盘

3.  level 1-n中子树，都是排序好的顺序内容

4. 每一层子树又有大小阈值，超过阈值就会进行合并，写入下一层

5.  只有内存中数据可以原地更新，磁盘上的数据只允许追加，通过compact方式合并（相同的值采用最新的值）

   ![image-20220226111632073](http://pedro-imgsubmit.oss-cn-beijing.aliyuncs.com/img/image-20220226111632073.png)

   ### 2.2 操作

   插入：无脑的往level0 内存中插入

   删除： 1.数据在内存中，则插入删除标识将其覆盖

   ​             2.数据在磁盘中，往level0中插入删除标识。后续会compact

   ​             3.数据不存在，继续往level0中插入删除标识

   修改：1.数据在内存level0中，原地修改

   ​            2.数据在磁盘中，往level0中插入。后续会compact

   ​             3.数据不存在，继续往level0中插入查询：一层一层的查询，查询到的一定是最新的合并：层层归并，归并保留新值

​       总结：牺牲了部分读性能，换取了强大的写性能；更适合写吞吐量大的场景



 

# 三  Art-tree（adaptive radix tree)

论文（https://db.in.tum.de/~leis/papers/ART.pdf）认为

- B+由于其在page内进行二分比较时，对分支预测不友好，无法充分利用现代cpu的能力
- 哈希表这样的结构，虽然查找很快，但是只能支持点查(where col = arg)而无法进行范围查找

而基数表具有以下两个优势：

1. 基数树的查找不需要二分，假设需要在下图查找"ART", 可以简单的通过数组操作定位到叶子节点
2. 基数树是有序的，支持范围查询

<img src="https://blog-image-1258275666.cos.ap-chengdu.myqcloud.com/Redix-Tree.png" alt="img" style="zoom:50%;" />

基数树最大的问题是空间利用率不高，art优化如下：

Node4：有key char[4]和children Node*[4]两部分。key数组内部是有序的。可放到L1Cache中

Node16：跟node4类似，可以利用simd指令，并行处理

Node48：由一个长度为 256 的 byte 数组和长度为 48 的指针数组构成，最多存储 48 个不同的 key 及其对应的子节点指针。一共占用 640（256*1 + 48*8）bytes

Node256，由长度为 256 的指针数组构成，一共占用 2048（256 * 8）bytes。有效指针个数在 49~256 时



**并发控制：**

并发版本的ART来自于ART作者的另一篇论文，[The ART of Practical Synchronization](https://link.zhihu.com/?target=https%3A//db.in.tum.de/~leis/papers/artsync.pdf)，文章提出了乐观锁版本的ART。

1.写操作：对记录加写锁，与其他写操作互斥；记录有版本号，每次写锁释放即更新完成后，递增版本号。

2.读操作：读之前和读之后都会检查记录是否有写锁，有的话说明其他线程当前在对其做修改，

3. 重试；读之前保存记录版本号v1，读完成之后检查版本号v2，如果v1 != v2，则说明记录被修改过，重试。



还有其他几种索引结构比如masstree， bw-tree。只有paper没有开源项目使用，暂不介绍

各索性性能比较：https://www.cs.cmu.edu/~huanche1/publications/open_bwtree.pdf

<img src="https://blog-image-1258275666.cos.ap-chengdu.myqcloud.com/Index-Performance.png" alt="img" style="zoom:50%;" />

# 四：B+tree在mysql的实现

##    4.1基础知识

###     **物理记录（record）**

​    mysql 中物理记录有两种格式，分别是redundant 和compact。从5.0后使用的是compact格式。

<img src="https://i-blog.csdnimg.cn/blog_migrate/8126cddf3e8e8841f9ddb096c818b9ca.png" alt="img" style="zoom:50%;" />

**其中头部信息结构如下**：

![row_format](http://mysql.taobao.org/monthly/pic/202003/2020-03-03-hangfeng-row-format.png)

​	1. Lengths of variable-length columns：只记录所有变长列的长度。每个变长列只占1 或2个字节。因此变长列的最大长度为2^16 = 65535

2. NULL columns bitmap：每个列占一个 bit，标识这个列是否是 NULL；如果是 NULL 则不再占用具体的数据空间

3. Extra bytes（REC_N_NEW_EXTRA_BYTES，5 byte）：

  4. - info bits（REC_NEW_INFO_BITS，4 bits）：预留两个 bit

     - - 一个 bit 是 REC_INFO_DELETED_FLAG，record 是否是 delete mark
       - 一个 bit 是 REC_INFO_MIN_REC_FLAG，record 是 B-Tree 这一层级最左边的节点

     - n_owned（REC_NEW_N_OWNED，4 bits）：大于 0 表示 record 占用一个 page directory slot 及该 slot 拥有的 record 数目

     - heap no（REC_NEW_HEAP_NO，13 bits）：record 在数据页内的 id（heap no 相邻的 record 不表示物理上相邻）

     - record status（REC_NEW_STATUS，3 bits）：record 的类型

     - - REC_STATUS_ORDINARY：叶子节点 record
       - REC_STATUS_NODE_PTR：中间节点 record
       - REC_STATUS_INFIMUM：[infimum record](https://zhida.zhihu.com/search?content_id=124735082&content_type=Article&match_order=1&q=infimum+record&zhida_source=entity)
       - REC_STATUS_SUPREMUM：[supremum record](https://zhida.zhihu.com/search?content_id=124735082&content_type=Article&match_order=1&q=supremum+record&zhida_source=entity)

     - record next（REC_NEXT，16 bits）：两个字节，指向下一个 record 的指针

       

       **隐藏列**有三列：DB_ROW_ID、DB_TRX_ID、DB_ROLL_PTR

     

     **数据列**Data contents：真正的数据（不包括 NULL 的列）。每一列的偏移由 rec_init_offsets 函数得到

     

     ```
     mysql> select * from t1;
     +------+------+------+
     | a    | b    | c    |
     +------+------+------+
     |    1 | aa   | bb   |
     |    2 | aaaa | bbbb |
     +------+------+------+
     2 rows in set (0.00 sec)
     
     hexdump -C t1.ibd
     
     00010070  73 75 70 72 65 6d 75 6d  02 02 00 00 00 10 00 23  |supremum.......#|
     00010080  00 00 05 f5 ee 02 00 00  06 05 74 d9 82 00 00 00  |...��.....t�....|
     00010090  ba 01 10 80 00 00 01 61  61 62 62 04 04 00 00 00  |�......aabb.....|
     000100a0  18 ff cd 00 00 05 f5 ee  03 00 00 06 05 74 dc 82  |.��...��.....t�.|
     000100b0  00 00 00 bb 01 10 80 00  00 02 61 61 61 61 62 62  |...�......aaaabb|
     000100c0  62 62 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |bb..............|
     000100d0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
     
     第一行记录一般从supremum结束后开始：
     ```

     | 起始地址 | 数据                 | 长度 | 解析                                               |
     | -------- | -------------------- | ---- | -------------------------------------------------- |
     | 00010078 | 02 02                | 2    | 变长字段长度列表，逆序存储（第一个02是c的长度...） |
     | 0001007a | 00                   | 1    | NULL标志位，表示这一行没有null                     |
     | 0001007b | 00 00 10 00 23       | 5    | 最后2字节是next_record=0x23(35字节)                |
     | 00010080 | 00 00 05 f5 ee 02    | 6    | row_id                                             |
     |          | 00 00 06 05 74 d9    | 6    | Trx_id                                             |
     |          | 82 00 00 00 ba 01 10 | 7    | DB_ROLL_PTR                                        |
     |          | 80 00 00 01          | 4    | a列信息，int 有符号4字节                           |
     |          | 61  61               | 2    | b列信息                                            |
     |          | 62 62                | 2    | c列信息                                            |

     35= 6+6+7+4+2+2（本rec）+ 2+1+5（next_rec_header）

     

     

     索引 page 和 record 的物理格式（page_t 和 rec_t）:

     ![image-20250410103224235](/Users/yangjinyin/Library/Application Support/typora-user-images/image-20250410103224235.png)

     ### 逻辑记录（tuple）

     <img src="/Users/yangjinyin/Library/Application Support/typora-user-images/image-20250410103549737.png" alt="image-20250410103549737" style="zoom: 25%;" />

     n_fields：列的数量

     fields：列（dfield_t）的数组，存储指向每一列真实数据的指针

     tuple_list：连接多个 tuple（每个索引都有一个 tuple，比如 INSERT SQL 需要向主键索引和二级索引中都插入时）

     

  15. ```cpp
      struct dfield_t{
          void*  data;      // 真实列数据的指针
          unsigned  ext:1;  // 如果是大记录（blob），则在外部页存储
          unsigned  len:32; // 列数据的长度    
          dtype_t  type;    // 列数据的类型
      };
      ```

​      



##       4.2 Innodb 的索引全貌

<img src="https://pic3.zhimg.com/v2-4b74551a141ce29a686b24e95c36f4d6_r.jpg" alt="img" style="zoom:33%;" />

​    1. 每一个record由 key + value 组成：中间节点的key 保存的是子节点中最小的key，value指向子节点。

​    2. 同一高度的 page 连接成 **双向链表**，称作 page list

​    3. 同一 page 的 record 连接成 **单向链表**，称作 record list（按 record key 升序连接）。数据页内的 record 逻辑上相邻，物理上不一定相邻

    4. Infimum record（下确界）/ supremum record（上确界）：两个系统记录（具有固定页内偏移量），为一个 page 内 record list 的头/尾节点



search_mode: 有4中搜索方式，分别是：

- PAGE_CUR_G（>，大于）：SELECT * WHERE column > 1
- PAGE_CUR_GE（>=，大于等于）：UPDATE / DELETE / SELECT * WHERE column = 1
- PAGE_CUR_L（<，小于）：SELECT * WHERE column < 1
- PAGE_CUR_LE（<=，小于等于）：INSERT ...

Latch mode：并发控制使用。(mysql中lacth 管理的是物理数据页，比如mtr的管理。lock是管理逻辑操作，比如表加lock，事务加锁等等) 一共有9种。

```cpp
/** Latching modes for btr_cur_search_to_nth_level(). */
enum btr_latch_mode : size_t {  
  /** Search a record on a leaf page and S-latch it. */
  BTR_SEARCH_LEAF,
  /** (Prepare to) modify a record on a leaf page and X-latch it. */
  BTR_MODIFY_LEAF,
  /** Obtain no latches. */
  BTR_NO_LATCHES,
  /** Start modifying the entire B-tree. */
  BTR_MODIFY_TREE = 33,
  /** Continue modifying the entire B-tree. */
  BTR_CONT_MODIFY_TREE = 34,
  /** Search the previous record. */
  BTR_SEARCH_PREV = 35,
  /** Modify the previous record. */
  BTR_MODIFY_PREV = 36,
  /** Start searching the entire B-tree. */
  BTR_SEARCH_TREE = 37,
  /** Continue searching the entire B-tree. */
  BTR_CONT_SEARCH_TREE = 38
};
```

**1. BTR_SEARCH_LEAF（点查询）**

- 获得索引的 S lock
- **由上至下**依次获取搜索路径节点的 S lock，直至叶子节点
- 释放索引和中间节点的 S lock，仅保留叶子节点
- 读叶子节点的内容 ......
- 释放叶子节点 S lock

 

 **2.BTR_MODIFY_LEAF（乐观写）**

- 获得索引的 S lock
- 自上而下获取S lock
- 叶子节点获取X lock
- 释放索引以及中间节点的S lock
- 修改叶子节点内容
- 释放叶子节点 X lock



**3. BTR_MODIFY_TREE（悲观写）**

 会引起SMO的操作

- 获得索引的 SX lock
- 自上而下依次获取 **可能引起分裂或者合并的节点**的X LOCK
- 依次获得叶子节点左兄弟，自身，右兄弟的X lock
- 修改中间节点和叶子节点的内容 ......
- 释放所有的X lock



4. **BTR_CONT_MODIFY_TREE**

​    使用于在 B-tree 分裂过程中，搜索得到叶子节点的父节点，或向父节点中插入新的 node ptr 的情况

5. **BTR_SEARCH_PREV（向前读）**

​    这种 latch mode 使用于逆向遍历 B-tree 叶子节点时

​    6 **BTR_MODIFY_PREV**

​    与 BTR_SEARCH_PREV 的区别在于对叶子节点加锁是 x latch。只有在向 Change Buffer 里插入时会使用这个 latch mode

7. **BTR_SEARCH_TREE**

​     在扫描 B-tree 收集统计信息时用到，e.g dict_stats_analyze_index_level

8. **BTR_CONT_SEARCH_TREE**

   仅在 btr_validate_level 中获得父节点时使用，进行 B-tree 结构合法性的检验

9. **BTR_NO_LATCHES**

   只对 intrinsic tables 的访问时用到

### 4.2.1 smo

InnoDB SMO的加锁流程（简化起见，假设本次SMO只需分裂leaf page）：

1. 对全局index->lock加SX锁
2. 从root page开始，以不加锁的方式向下遍历non-leaf pages至level 2
3. 对level 1的non-leaf page加X锁
4. 对level 0的leaf page及其left、right page加X锁，完成leaf page的SMO
5. 从root page开始，以不加锁的方式向下遍历至leaf page的parent
6. 向parent page插入SMO中对应指向new page的nodeptr
7. 释放所有锁，SMO结束

这里可以看到有下面2个瓶颈点：

1. 对于单个SMO来说，参与SMO的leaf pages及其parent page的X锁会从一开始加着直到SMO结束，这样的加锁粒度有些大，其实SMO也是分层、从下到上依次操作的，如上面流程中：步骤4先在level 0对leaf page做分裂，然后再在步骤5向parent page插入指向new page的nodeptr，但其实在做步骤4的时候没必要先加着parent page X锁，同样再步骤5中也没必要还占着leaf pages X锁，这个问题在级联SMO场景（leaf page分裂引发其路径上多个non-leaf pages分裂）更为明显，这样在读写混合场景下，SMO路径上的读性能会受影响
2. 虽然SMO对index->lock加了SX锁，可以允许其他非SMO操作并发进来，但SX之间还是互斥的，也就是说多个SMO并不能并发，即使它们之间完全没有page交集，这样在高并发大写入压力下（剧烈触发SMO）性能不理想

## 4.3 Persistent cursor（持久化游标）

​     cursor 是一个逻辑的概念，产生于对 B-tree 遍历的需求。表示在 B-tree 上遍历至某一个位置（某个 block，其上的某个 record），包括 B-tree cursor（btr_cur_t） 和 page cursor（page_cur_t）

```cpp
/* The tree cursor */
struct btr_cur_t {
  dict_index_t*  index;
  page_cur_t  page_cur; // 遍历至 B-tree 的某个 page
  ulint tree_height
  ...
}

/** Index page cursor */
struct page_cur_t {
  const dict_index_t *index{nullptr};
  rec_t *rec{nullptr}; /*!< pointer to a record on page */
  ulint *offsets{nullptr};
  buf_block_t *block{nullptr}; /*!< pointer to the block containing rec */
};
```

当然innodb层为了减少查找的开销，做了以下几点优化

1. **record buffer**：对于连续的记录扫描，在满足比较严格的条件时采用 record buffer（又叫 pre-fetch queue）的方式连续读取 8 条（MYSQL_FETCH_CACHE_SIZE）记录，将记录格式转换成 MySQL format 存储在线程私有的 row_prebuilt_t::fetch_cache 中；这样一次查找就可以获取多条记录，在 SQL 层处理完一条记录后，可以直接从 record buffer 中直接拿数据而无需再次寻路，直到record buffer 中数据取完，再进行下一轮查找。
2. **persistent cursor**（持久化游标，简称 pcur）：当进入 InnoDB 层获得记录后，返回 SQL 层前，当前在 B-tree 上的 cursor 会被暂时存储到 row_prebuilt_t::pcur 中，当再次从 InnoDB 层拿数据时，如果对应的 buf_block_t 没有发生任何修改，则可以继续沿用之前存储的 cursor（optimistic restore cursor）。否则需要重新定位（pessimistic restore cursor）。如果没有 persistent cursor 则每次都需要重新定位
3. **Adaptive Hash Index（AHI）**：适合大数据量场景，当索引层数比较高的时候。innodb会自适应建立一个hashtable，可以直接定位到具体的page，而无需遍历中间节点。

## 4.4 index scan的核心流程

1. Server 选择合适的索引（或者无合适的索引），根据 WHERE 条件构建 search tuple，首次调用 InnoDB 的接口获得下一个记录行
2. InnoDB 在索引中自顶向下查找 search tuple，将 cursor 放置于 search tuple 等价的 record 处，并 "store cursor"
3. Server 判断返回的记录是否满足要求，再次调用 InnoDB 的接口（handler）获得下一个记录行
4. InnoDB restore cursor，将 cursor 正序（逆序）移动到下一个 record，并返回给 Server
5. 重复 3~4 步 ...

核心函数:

- row_search_mvcc：从InnoDB获取数据行的入口函数
- btr_cur_search_to_nth_level：由顶之下的查找整个 B-tree的。btree的并发控制
- page_cur_search_with_match：在一个数据页内“二分查找”，定位到 record
- cmp_dtuple_rec_with_match_low：比较定位的 record 是否是需要的 record



### 4.4.1 row_search_mvcc()

<img src="https://picx.zhimg.com/v2-913271b883a979b7bf13e94c6d0a56c5_r.jpg" alt="img" style="zoom: 150%;" />

```c++
dberr_t row_search_mvcc(byte *buf, page_cur_mode_t mode,
                        row_prebuilt_t *prebuilt, ulint match_mode,
                        const ulint direction) {
  /* 检查当前索引是否是FTS,全文索引*/
  if (prebuilt->index->type & DICT_FTS) {
    return DB_END_OF_INDEX;
  }
  
  //表是否discard
  if (dict_table_is_discarded(prebuilt->table)) {
    return DB_TABLESPACE_DELETED;

  } else if (prebuilt->table->ibd_file_missing) {
    //表中ibd文件是否存在
    return DB_TABLESPACE_NOT_FOUND;

  } else if (!prebuilt->index_usable) {
    //对于本次事务，这个索引是否可见
    return DB_MISSING_HISTORY;

  } else if (prebuilt->index->is_corrupted()) {
    //索引是否损坏
    return DB_CORRUPTION;
  }
  ...
  //首次进入，初始化状态
  if (UNIV_UNLIKELY(direction == 0)) {
    trx->op_info = "starting index read";

    prebuilt->n_rows_fetched = 0;
    prebuilt->n_fetch_cached = 0;
    prebuilt->fetch_cache_first = 0;
    prebuilt->m_end_range = false;
    if (record_buffer != nullptr) {
      record_buffer->reset();
    }
  } else {   
    // 如果查询方向改变，则说明之前的缓存没有用了，清空即可.后续会预读新的数据
    if (UNIV_UNLIKELY(direction != prebuilt->fetch_direction)) {

      prebuilt->n_rows_fetched = 0;
      prebuilt->n_fetch_cached = 0;
      prebuilt->fetch_cache_first = 0;
      prebuilt->m_end_range = false;

      /* A record buffer is not used for scroll cursors.
      Otherwise, it would have to be reset here too. */
      ut_ad(record_buffer == nullptr);

    } else if (UNIV_LIKELY(prebuilt->n_fetch_cached > 0)) {
      // 方向相同，且缓存中还有未读取的行，直接使用缓存数据即可
      row_sel_dequeue_cached_row_for_mysql(buf, prebuilt);

      prebuilt->n_rows_fetched++;

      err = DB_SUCCESS;
      goto func_exit;
    } else if (prebuilt->m_end_range) {
      err = DB_RECORD_NOT_FOUND;
      goto func_exit;
    }
  }

  /* 对唯一索引模式进行判断: 
   1. 是准确查找，而不是最左匹配，即match_mode == ROW_SEL_EXACT
   2.查询条件涵盖所有索引列
   3. 索引为唯一索引，当然聚集索引也是唯一索引，如果非聚集索引的唯一索引还要求索引条件不能包含null
   这样方便后面AHI优化 */
  if (match_mode == ROW_SEL_EXACT && dict_index_is_unique(index) &&
      dtuple_get_n_fields(search_tuple) == dict_index_get_n_unique(index) &&
      (index->is_clustered() || !dtuple_contains_null(search_tuple))) 
    unique_search = true;
  }

  //下面开始对索引树进行操作
  mtr_start(&mtr);

  //unique_search 唯一索引模式进行走AHI判断
  if (UNIV_UNLIKELY(direction == 0) && unique_search && btr_search_enabled &&
      index->is_clustered() && !prebuilt->templ_contains_blob &&
      !prebuilt->used_in_HANDLER &&
      (prebuilt->mysql_row_len < UNIV_PAGE_SIZE / 8) && !prebuilt->innodb_api) {
    ...
  }

  /*定位游标，确定是否需要gap锁
   1.操作的表为元数据表或者SDI表（非innodb表的元数据信息），即prebuilt->table->skip_gap_locks()
   2.事务隔离级别无须间隙锁，trx->skip_gap_locks()，即隔离级别小于RR;执行select语句且采用快照读，不加锁*/
  if (prebuilt->table->skip_gap_locks() ||
      (trx->skip_gap_locks() && prebuilt->select_lock_type != LOCK_NONE &&
       trx->mysql_thd != nullptr && thd_is_query_block(trx->mysql_thd))) {
    set_also_gap_locks = false;
  }

  //确定是否需要回表，对于二级索引，如果索引不能满足所有要求列，则需要回表
  clust_templ_for_sec =
      index != clust_index && prebuilt->need_to_access_clustered;

  if (!prebuilt->sql_stat_start) {
    /* 如果已经添加了表锁或者分配了快照则不进行相关操作 */
    if (!MVCC::is_view_active(trx->read_view) && !srv_read_only_mode &&
        prebuilt->select_lock_type == LOCK_NONE) {
      ib::error(ER_IB_MSG_1031) << "MySQL is trying to perform a"
                                   " consistent read but the read view is not"
                                   " assigned!";
      trx_print(stderr, trx, 600);
      fputc('\n', stderr);
      ut_error;
    }
  } else if (prebuilt->select_lock_type == LOCK_NONE) {
    /* 一致性读，则分配一个视图 */
    if (!srv_read_only_mode) {
      trx_assign_read_view(trx);
    }
    prebuilt->sql_stat_start = false;
  } else {
  wait_table_again:
   // 如果当前读，则进行表锁获取（可能IS或者IX）
    err = lock_table(0, index->table,
                     prebuilt->select_lock_type == LOCK_S ? LOCK_IS : LOCK_IX,
                     thr);

    if (err != DB_SUCCESS) {
      table_lock_waited = true;
      goto lock_table_wait;
    }
    prebuilt->sql_stat_start = false;
  }

  if (UNIV_LIKELY(direction != 0)) {
    if (spatial_search) {
      /* R-Tree access does not need to do
      cursor position and resposition */
      goto next_rec;
    }

    /*sel_restore_position_for_mysql()很重要，恢复游标位置
     1. 乐观恢复：之前指向数据页的 modify clock若没有改变，则可以直接 latch 住该页 restore cursor 完成
     2. 悲观恢复：之前指向数据页的 modify clock 有改变（数据页上的记录被修改），则需要重新遍历btree*/
    auto need_to_process = sel_restore_position_for_mysql(
        &same_user_rec, BTR_SEARCH_LEAF, pcur, moves_up, &mtr);

    ut_ad(prev_rec == nullptr);

    if (UNIV_UNLIKELY(need_to_process)) {
      //tree代表游标还不能移动到下一个位置
      prebuilt->row_read_type = ROW_READ_TRY_SEMI_CONSISTENT;
    } else if (UNIV_LIKELY(prebuilt->row_read_type !=
                           ROW_READ_DID_SEMI_CONSISTENT)) {
      /* The cursor was positioned on the record
      that we returned previously.  If we need
      to repeat a semi-consistent read as a
      pessimistic locking read, the record
      cannot be skipped. */

      goto next_rec;
    }

  } else if (dtuple_get_n_fields(search_tuple) > 0) {
    // 用于index scan
   
    pcur->m_btr_cur.thr = thr;

    if (dict_index_is_spatial(index)) {
      bool need_pred_lock = set_also_gap_locks && !trx->skip_gap_locks() &&
                            prebuilt->select_lock_type != LOCK_NONE;

      if (!prebuilt->rtr_info) {
        prebuilt->rtr_info = rtr_create_rtr_info(need_pred_lock, true,
                                                 pcur->get_btr_cur(), index);
        prebuilt->rtr_info->search_tuple = search_tuple;
        prebuilt->rtr_info->search_mode = mode;
        rtr_info_update_btr(pcur->get_btr_cur(), prebuilt->rtr_info);
      } else {
        rtr_info_reinit_in_cursor(pcur->get_btr_cur(), index, need_pred_lock);
        prebuilt->rtr_info->search_tuple = search_tuple;
        prebuilt->rtr_info->search_mode = mode;
      }
    }

    // 尚未放置cursor，从顶至下遍历 B-tree，根据 search tuple 放置  cursor 
    pcur->open_no_init(index, search_tuple, mode, BTR_SEARCH_LEAF, 0, &mtr,
                       UT_LOCATION_HERE);

    pcur->m_trx_if_known = trx;

    rec = pcur->get_rec();

    if (!moves_up && !page_rec_is_supremum(rec) && set_also_gap_locks &&
        !trx->skip_gap_locks() && prebuilt->select_lock_type != LOCK_NONE &&
        !dict_index_is_spatial(index)) {
       /* 对于降序扫描，第一条满足条件的下一条记录需要添加gap锁 */
      const rec_t *next_rec = page_rec_get_next_const(rec);

      offsets = rec_get_offsets(next_rec, index, offsets, ULINT_UNDEFINED,
                                UT_LOCATION_HERE, &heap);
      err = sel_set_rec_lock(pcur, next_rec, index, offsets,
                             prebuilt->select_mode, prebuilt->select_lock_type,
                             LOCK_GAP, thr, &mtr);

      switch (err) {
        case DB_SUCCESS_LOCKED_REC:
          err = DB_SUCCESS;
        case DB_SUCCESS:
          break;
        case DB_SKIP_LOCKED:
        case DB_LOCK_NOWAIT:
          ut_d(ut_error);
          ut_o(goto next_rec);
        default:
          goto lock_wait_or_error;
      }
    }
  } else if (mode == PAGE_CUR_G || mode == PAGE_CUR_L) {
    // 如果table scan,直接定位到 B-tree 左边
    pcur->open_at_side(mode == PAGE_CUR_G, index, BTR_SEARCH_LEAF, false, 0,
                       &mtr);
  }

rec_loop:
  /*-------------------------------------------------------------*/
  /* PHASE 4: Look for matching records in a loop */
  //得到 cursor 指向的 record
  rec = pcur->get_rec();

  if (match_mode == ROW_SEL_EXACT) {
    /* 如果是点查完全匹配 把record加锁，并返回recored*/
    if (0 != cmp_dtuple_rec(search_tuple, rec, index, offsets)) {
      if (set_also_gap_locks && !trx->skip_gap_locks() &&
          prebuilt->select_lock_type != LOCK_NONE &&
          !dict_index_is_spatial(index)) {
        err = sel_set_rec_lock(pcur, rec, index, offsets, prebuilt->select_mode,
                               prebuilt->select_lock_type, LOCK_GAP, thr, &mtr);

        switch (err) {
          case DB_SUCCESS_LOCKED_REC:
          case DB_SUCCESS:
            break;
          case DB_SKIP_LOCKED:
          case DB_LOCK_NOWAIT:
            ut_d(ut_error);
          default:
            goto lock_wait_or_error;
        }
      }
      //保存cursor，很重要
      pcur->store_position(&mtr);
    }

  } else if (match_mode == ROW_SEL_EXACT_PREFIX) {
    //最左匹配  eg: select xx from xx where xxx like 'test%'
    if (!cmp_dtuple_is_prefix_of_rec(search_tuple, rec, index, offsets)) {
      if (set_also_gap_locks && !trx->skip_gap_locks() &&
          prebuilt->select_lock_type != LOCK_NONE &&
          !dict_index_is_spatial(index)) {
        err = sel_set_rec_lock(pcur, rec, index, offsets, prebuilt->select_mode,
                               prebuilt->select_lock_type, LOCK_GAP, thr, &mtr);

        switch (err) {
          case DB_SUCCESS_LOCKED_REC:
          case DB_SUCCESS:
            break;
          case DB_SKIP_LOCKED:
          case DB_LOCK_NOWAIT:
            ut_d(ut_error);
          default:
            goto lock_wait_or_error;
        }
      }

      pcur->store_position(&mtr);
  }

  // 当前读模式。有锁读的话则 record 加锁（lock） eg:select * for update, select * lock in share mode；无锁读不需要锁（MVCC）
  if (prebuilt->select_lock_type != LOCK_NONE) {
    auto row_to_range_relation = row_compare_row_to_range(
        set_also_gap_locks, trx, unique_search, index, clust_index, rec, comp,
        mode, direction, search_tuple, offsets, moves_up, prebuilt);

    ulint lock_type;
    if (row_to_range_relation.row_can_be_in_range) {
      if (row_to_range_relation.gap_can_intersect_range) {
        lock_type = LOCK_ORDINARY;      
      } else {
        lock_type = LOCK_REC_NOT_GAP;
      }
    } else {
      if (row_to_range_relation.gap_can_intersect_range) {
        lock_type = LOCK_GAP;
      } else {
        err = DB_RECORD_NOT_FOUND;
        goto normal_return;
      }
    }
    /* in case of semi-consistent read, we use SELECT_SKIP_LOCKED, so we don't
    waste time on creating a WAITING lock, as we won't wait on it anyway */
    const bool use_semi_consistent =
        prebuilt->row_read_type == ROW_READ_TRY_SEMI_CONSISTENT &&
        !unique_search && index == clust_index && !trx_is_high_priority(trx);
    err = sel_set_rec_lock(
        pcur, rec, index, offsets,
        use_semi_consistent ? SELECT_SKIP_LOCKED : prebuilt->select_mode,
        prebuilt->select_lock_type, lock_type, thr, &mtr);

    switch (err) {
      const rec_t *old_vers;
      case DB_SUCCESS_LOCKED_REC:
        if (trx->releases_non_matching_rows()) {
          /* Note that a record of
          prebuilt->index was locked. */
          ut_ad(!prebuilt->new_rec_lock[row_prebuilt_t::LOCK_PCUR]);
          prebuilt->new_rec_lock[row_prebuilt_t::LOCK_PCUR] = true;
        }
        err = DB_SUCCESS;
        [[fallthrough]];
      case DB_SUCCESS:
        if (row_to_range_relation.row_must_be_at_end) {
          prebuilt->m_stop_tuple_found = true;
        }
        break;
      case DB_SKIP_LOCKED:
        if (prebuilt->select_mode == SELECT_SKIP_LOCKED) {
          goto next_rec;
        }
        DEBUG_SYNC_C("semi_consistent_read_would_wait");
        ut_a(use_semi_consistent);
        ut_a(trx->allow_semi_consistent());
        /* The following call returns 'offsets' associated with 'old_vers' */
        row_sel_build_committed_vers_for_mysql(
            clust_index, prebuilt, rec, &offsets, &heap, &old_vers,
            need_vrow ? &vrow : nullptr, &mtr);

        ut_ad(!dict_index_is_spatial(index));
        err = DB_SUCCESS;

        if (old_vers == nullptr) {
          /* The row was not yet committed */
          goto next_rec;
        }

        did_semi_consistent_read = true;
        rec = old_vers;
        prev_rec = rec;
        ut_d(prev_rec_debug = row_search_debug_copy_rec_order_prefix(
                 pcur, index, prev_rec, &prev_rec_debug_n_fields,
                 &prev_rec_debug_buf, &prev_rec_debug_buf_size));
        break;
      case DB_LOCK_WAIT:
        /* Lock wait for R-tree should already
        be handled in sel_set_rtr_rec_lock() */
        ut_ad(!dict_index_is_spatial(index));
        /* Never unlock rows that were part of a conflict. */
        prebuilt->new_rec_lock.reset();
        ut_a(!use_semi_consistent);
        goto lock_wait_or_error;
      case DB_RECORD_NOT_FOUND:
        if (dict_index_is_spatial(index)) {
          goto next_rec;
        } else {
          goto lock_wait_or_error;
        }

      default:
        ut_a(!use_semi_consistent);
        goto lock_wait_or_error;
    }
    if (err == DB_SUCCESS && !row_to_range_relation.row_can_be_in_range) {
      err = DB_RECORD_NOT_FOUND;
      goto normal_return;
    }
  } else {
    /* This is a non-locking consistent read: if necessary, fetch
    a previous version of the record */

    if (trx->isolation_level == TRX_ISO_READ_UNCOMMITTED) {
      //1. RU级别，不做处理

    } else if (index == clust_index) {
      if (srv_force_recovery < 5 && trx_id_t sees_or_wait = lock_clust_rec_cons_read_sees_ex(rec, index, offsets,
        trx_get_read_view(trx)))  { //当前行不可见

        ;
        if (sees_or_wait == 0) {
          rec_t *old_vers;
         // 2. 如果是聚簇索引，根据undo段直接构建可见的数据行版本，得到 result_rec
          err = row_sel_build_prev_vers_for_mysql(
              trx->read_view, clust_index, prebuilt, rec, &offsets, &heap,
              &old_vers, need_vrow ? &vrow : nullptr, &mtr,
                  prebuilt->get_lob_undo());

          if (err != DB_SUCCESS) {
            if (err == DB_STS_TOO_SMALL) {
              mtr_commit(&mtr);
              trx->error_state = err;
              que_thr_stop_for_mysql(thr);
              goto func_exit;
            }
            goto lock_wait_or_error;
          }

          if (old_vers == nullptr) {
            /* The row did not exist yet in
              the read view */

            goto next_rec;
          }

          rec = old_vers;
          prev_rec = rec;
          ut_d(prev_rec_debug = row_search_debug_copy_rec_order_prefix(
              pcur, index, prev_rec, &prev_rec_debug_n_fields,
              &prev_rec_debug_buf, &prev_rec_debug_buf_size));
        } else if (sees_or_wait > 1) {
          pcur->store_position(&mtr);
          mtr_commit(&mtr);
          if (trx_sys_wait_trx_commit(sees_or_wait, thr) != DB_BLOCKING_READ_WAIT_TIMEOUT) {
            mtr_start(&mtr);
            sel_restore_position_for_mysql(&same_user_rec, BTR_SEARCH_LEAF, pcur,
                                           moves_up, &mtr);
            goto rec_loop;
          }
          err = DB_BLOCKING_READ_WAIT_TIMEOUT;
          trx->error_state = err;
          que_thr_stop_for_mysql(thr);
          goto func_exit;
        }
      }
    } else {
      //3. 二级索引
       //  3.1 事务可见性判断
      //   3.2 ICP 判断：判断 rec 是否满足 ICP（index condition pushdown）

      if (!srv_read_only_mode &&
          !lock_sec_rec_cons_read_sees(rec, index, trx->read_view)) {
        //如果不可见，需要先进行索引下推判断，然后进行回表操作
        switch (row_search_idx_cond_check(buf, prebuilt, rec, offsets)) {
          case ICP_NO_MATCH:
            // 不满足 ICP，去拿下一个数据行
            goto next_rec;
          case ICP_OUT_OF_RANGE:
            err = DB_RECORD_NOT_FOUND;
            goto idx_cond_failed;
          case ICP_MATCH:
            // 满足 ICP，去拿主键索引数据行
            goto requires_clust_rec;
        }
      }
    }
  }

  if (rec_get_deleted_flag(rec, comp)) {
    /* 跳过被删除的记录，直接拿下一条记录 */
    goto next_rec;
  }

  /* ，需要先进行索引下推判断 */
  switch (row_search_idx_cond_check(buf, prebuilt, rec, offsets)) {
    case ICP_NO_MATCH:
      prebuilt->try_unlock(true);
      goto next_rec;
    case ICP_OUT_OF_RANGE:
      err = DB_RECORD_NOT_FOUND;
      prebuilt->try_unlock(true);
      goto idx_cond_failed;
    case ICP_MATCH:
      break;
  }

  //如果是二级索引，并且是需要回表的
  if (index != clust_index && prebuilt->need_to_access_clustered) {
  requires_clust_rec:

    //回表，拿到数据
    err = row_sel_get_clust_rec_for_mysql(
        prebuilt, index, rec, thr, &clust_rec, &offsets, &heap,
        need_vrow ? &vrow : nullptr, &mtr, prebuilt->get_lob_undo(), &wait_trx_id);

     // ...
    //mtr_commit(&mtr);pcur->store_position(&mtr);

    if (rec_get_deleted_flag(clust_rec, comp)) {
       /* 跳过被删除的记录，直接拿下一条记录 */

      goto next_rec;
    }

    if (need_vrow && !vrow) {
      // 存在虚拟列，则构建
      if (!heap) {
        heap = mem_heap_create(100, UT_LOCATION_HERE);
      }
      row_sel_fill_vrow(rec, index, &vrow, heap);
    }

    result_rec = clust_rec;

    if (prebuilt->idx_cond) {
      //格式转换
      if (!row_sel_store_mysql_rec(buf, prebuilt, result_rec, vrow, true,
                                   clust_index, prebuilt->index, offsets, false,
                                   nullptr, prebuilt->blob_heap)) {
        goto next_rec;
      }
    }
  }

  if (record_buffer != nullptr ||
      ((match_mode == ROW_SEL_EXACT ||
        prebuilt->n_rows_fetched >= MYSQL_FETCH_CACHE_THRESHOLD) &&
       prebuilt->can_prefetch_records())) { //缓存预读
   

    const auto max_rows_to_cache =
        record_buffer ? record_buffer->max_records() : MYSQL_FETCH_CACHE_SIZE;
    ut_a(prebuilt->n_fetch_cached < max_rows_to_cache);

    if (!prebuilt->idx_cond) {
      //非ICP场景读取逻辑
      byte *prev_buf = next_buf;

      next_buf = next_buf ? row_sel_fetch_last_buf(prebuilt) : buf;

      if (!row_sel_store_mysql_rec(
              next_buf, prebuilt, result_rec, vrow, result_rec != rec,
              result_rec != rec ? clust_index : index, prebuilt->index, offsets,
              false, nullptr, prebuilt->blob_heap)) {
        goto next_rec;
      }

      ...
      //预读多行数据，把结果压到record buffer。
      row_sel_enqueue_cache_row_for_mysql(buf, prebuilt);
    }
  } else {
    ...
    
    }
  }
next_rec:

  if (moves_up) {
    
    bool move;
    if (spatial_search) {
      move = rtr_pcur_move_to_next(search_tuple, mode, prebuilt->select_mode,
                                   pcur, 0, &mtr);
    } else {
      //移动到后一个 record，如果需要则移动到后一个数据页
      move = pcur->move_to_next(&mtr);
    }

    if (!move) { // 移动不了，达到最后一条记录
    not_moved:
      if (!spatial_search) {
        pcur->store_position(&mtr);
      }

      if (match_mode != 0) {
        err = DB_RECORD_NOT_FOUND;
      } else {
        err = DB_END_OF_INDEX;
      }

      goto normal_return;
    }
  } else { // 如果逆序查找，则游标向前移动，移动的处理与上述一致
    if (UNIV_UNLIKELY(!pcur->move_to_prev(&mtr))) {
      goto not_moved;
    }
  }
  goto rec_loop;
}
```

### 补充：ICP索引下推处理

```c++
|-->row_search_idx_cond_check()
|		|-->row_sel_store_mysql_field() //convert innodb field to mysql field
|		|-->innobase_index_cond() //icp判断
|		|		|-->handler::compare_key_icp() //判断是否<end_range内（主要用与range scan）
|		|		|-->Item_values_column::val_int()//不同对象调用不同的val_int进行比较
```



### 4.4.2 sel_restore_position_for_mysql()

adjust cursor的主要函数是sel_restore_position_for_mysql()

```cpp
static ibool sel_restore_position_for_mysql(...) {
  // 使用乐观或者悲观策略 restore cursor
  success = btr_pcur_restore_position(latch_mode, pcur, mtr);

  switch (pcur->m_rel_pos) {
    case BTR_PCUR_UNSET:
      ut_ad(0);
      return (TRUE);
    case BTR_PCUR_ON:
      // cursor 之前置于 user record，但 restore 之后没置于相同的 record。说明使用的是
      // 悲观策略。那么 search mode 是 PAGE_CUR_LE。此时 cursor 位于小于原 user record 
      // 的最大的 record。如果是正序遍历，此 record 必定已被处理，那么需要移动到下一个
      // record
      if (!success && moves_up) {
      next:
        btr_pcur_move_to_next(pcur, mtr);
        return (TRUE);
      }
      // 1. success 是 false && move_up 是 false
      // cursor 之前置于 user record，但 restore 之后没置于相同的 record，
      // 此时 cursor 位于小于原 user record 的最大的 record；如果是逆序遍历那么此时的
      // record 没有被处理，返回 true（需要被处理）
      // 2. success 是 true，说明 cursor resotre 之后置于相同的 record。此 record
      // 之前已被处理过（处理完才可能 store cursor），则返回 false
      return (!success);
    case BTR_PCUR_AFTER_LAST_IN_TREE:
    case BTR_PCUR_BEFORE_FIRST_IN_TREE:
      return (TRUE);
    case BTR_PCUR_AFTER:
      /* positioned to record after pcur->old_rec. */
      pcur->m_pos_state = BTR_PCUR_IS_POSITIONED;
      // cursor 之前置于 supremum record，restore 之后置于 user record 而且是逆序遍历
      // 则将 cursor 再移动到逆序的上一个 user record
      // 这种操作可以理解，比如两个顺序的页 P1->P2，P1 上记录是 INF->2->3->SUP，P2 上是 
      // INF->4->5->SUP，当 cursor 移动到 P1 SUP 时被 store。这时 cursor 里保存着 
      // old_rec 是 3（SUP 的前一个 user record），在 restore 时如果采用的是悲观策略
      // key 是 3，search mode 是 PAGE_CUR_G（>）。那么 restore 之后 cursor 置于 P2
      // 上的 4。如果是逆序遍历（!moves_up），说明 4 已经被遍历（cursor 在被 store 时就
      // 位于 P1 中了，说明 P2 已经被扫描），因此需要把 cursor 移动到前一个 user record
      //（记录 3）
    prev:
      if (btr_pcur_is_on_user_rec(pcur) && !moves_up) {
        btr_pcur_move_to_prev(pcur, mtr);
      }
      // 1. btr_pcur_is_on_user_rec(pcur) && moves_up，需要被处理所以 return (TRUE)。
      // 原因类似上文的分析
      // 2. !btr_pcur_is_on_user_rec(pcur)。为什么 restore cursor 后置于 infimum 或 
      // supremum record，B-tree 空了？
      return (TRUE);
    case BTR_PCUR_BEFORE:
      /* For non optimistic restoration:
      The position is now set to the record before pcur->old_rec.

      For optimistic restoration:
      The position also needs to take the previous search_mode into
      consideration. */

      switch (pcur->m_pos_state) {
        case BTR_PCUR_IS_POSITIONED_OPTIMISTIC:
          // cursor 之前置于 infimum record，而且是乐观策略 restore。因为乐观策略后
          // cursor 一定置于 m_old_record（infimum record 的后继 user record），
          // 如果是 PAGE_CUR_GE 模式（说明 scanning for lower？为何不用 move_up 
          // 判断）则将 cursor 再移动到逆序的上一个 user record。这里的缘故不太清楚 ...
          pcur->m_pos_state = BTR_PCUR_IS_POSITIONED;
          if (pcur->m_search_mode == PAGE_CUR_GE) {
            /* Positioned during Greater or Equal search
            with BTR_PCUR_BEFORE. Optimistic restore to
            the same record. If scanning for lower then
            we must move to previous record.
            This can happen with:
            HANDLER READ idx a = (const);
            HANDLER READ idx PREV; */
            goto prev;
          }
          return (TRUE);
        case BTR_PCUR_IS_POSITIONED:
          // 使用悲观策略，search mode 是 PAGE_CUR_L。比如两个顺序的页 P1->P2，P1 上记录
          // 是 INF->2->3->SUP，P2 上是 INF->4->5->SUP。cursor 在 P2 INF 时被 store
          // restore 后位于 P1 3 处。如果是正序遍历（moves_up）则 3 必定已被处理过，cursor
          // 移动到下一个 record
          if (moves_up && btr_pcur_is_on_user_rec(pcur)) {
            goto next;
          }
          return (TRUE);
        case BTR_PCUR_WAS_POSITIONED:
        case BTR_PCUR_NOT_POSITIONED:
          break;
      }
  }
}
```

### 4.4.3 btr_cur_search_to_nth_level()

由顶之下的查找整个 B-tree的。btree的并发控制

```c++
void btr_cur_search_to_nth_level(
    dict_index_t *index,   /*!< in: index */
    ulint level,           /*!< in: the tree level of search */
    const dtuple_t *tuple, /*!< in: data tuple; NOTE: n_fields_cmp in
                           tuple must be set so that it cannot get
                           compared to the node ptr page number field! */
    page_cur_mode_t mode,  /*!< in: PAGE_CUR_L, ...;
                           Inserts should always be made using
                           PAGE_CUR_LE to search the position! */
    ulint latch_mode,      /*!< in: BTR_SEARCH_LEAF, ..., ORed with
                       at most one of BTR_INSERT, BTR_DELETE_MARK,
                       BTR_DELETE, or BTR_ESTIMATE;
                       cursor->left_block is used to store a pointer
                       to the left neighbor page, in the cases
                       BTR_SEARCH_PREV and BTR_MODIFY_PREV;
                       NOTE that if has_search_latch
                       is != 0, we maybe do not have a latch set
                       on the cursor page, we assume
                       the caller uses his search latch
                       to protect the record! */
    btr_cur_t *cursor,     /*!< in/out: tree cursor; the cursor page is
                           s- or x-latched, but see also above! */
    ulint has_search_latch,
    /*!< in: info on the latch mode the
    caller currently has on search system:
    RW_S_LATCH, or 0 */
    const char *file, /*!< in: file name */
    ulint line,       /*!< in: line where called */
    mtr_t *mtr)       /*!< in: mtr */
{
 ...

  savepoint = mtr_set_savepoint(mtr);

  //根据不同的latch_mode，对index加s / x / sx 锁 
  switch (latch_mode) {
    case BTR_MODIFY_TREE:
      /* Most of delete-intended operations are purging.
      Free blocks and read IO bandwidth should be prior
      for them, when the history list is glowing huge. */
      if (lock_intention == BTR_INTENTION_DELETE &&
          trx_sys->rseg_history_len.load() > BTR_CUR_FINE_HISTORY_LENGTH &&
          buf_get_n_pending_read_ios()) {
        mtr_x_lock(dict_index_get_lock(index), mtr, UT_LOCATION_HERE);
      } else if (dict_index_is_spatial(index) &&
                 lock_intention <= BTR_INTENTION_BOTH) {
        /* X lock the if there is possibility of
        pessimistic delete on spatial index. As we could
        lock upward for the tree */

        mtr_x_lock(dict_index_get_lock(index), mtr, UT_LOCATION_HERE);
      } else {
       mtr_sx_lock(dict_index_get_lock(index), mtr, UT_LOCATION_HERE);
      }
      upper_rw_latch = RW_X_LATCH;
      break;
    case BTR_CONT_MODIFY_TREE:
    case BTR_CONT_SEARCH_TREE:
      /* Do nothing */
      if (dict_index_is_spatial(index) && latch_mode == BTR_CONT_MODIFY_TREE) {
        /* If we are about to locating parent page for split
        and/or merge operation for R-Tree index, X latch
        the parent */
        upper_rw_latch = RW_X_LATCH;
      } else {
        upper_rw_latch = RW_NO_LATCH;
      }
      break;
    default:
      if (!srv_read_only_mode) {
        if (s_latch_by_caller) {
          /* The BTR_ALREADY_S_LATCHED indicates that the index->lock has been
          taken either in RW_S_LATCH or RW_SX_LATCH mode. For parallel reads
          another thread can own the dict index lock. */
        } else if (!modify_external) {
          /* BTR_SEARCH_TREE is intended to be used with
          BTR_ALREADY_S_LATCHED */

          mtr_s_lock(dict_index_get_lock(index), mtr, UT_LOCATION_HERE);
        } else {
          /* BTR_MODIFY_EXTERNAL needs to be excluded */
          mtr_sx_lock(dict_index_get_lock(index), mtr, UT_LOCATION_HERE);
        }
        upper_rw_latch = RW_S_LATCH;
      } else {
        upper_rw_latch = RW_NO_LATCH;
      }
  }
  root_leaf_rw_latch = btr_cur_latch_for_root_leaf(latch_mode);

  page_cursor = btr_cur_get_page_cur(cursor);

  const space_id_t space = dict_index_get_space(index);
  const page_size_t page_size(dict_table_page_size(index->table));

  //从root page 开始
  page_id_t page_id(space, dict_index_get_page(index));

  if (root_leaf_rw_latch == RW_X_LATCH) {
    node_ptr_max_size = dict_index_node_ptr_max_size(index);
  }

  up_match = 0;
  up_bytes = 0;
  low_match = 0;
  low_bytes = 0;

  height = ULINT_UNDEFINED;

  //非叶子节点，根据mode 的不同，设置不同的search mode
  switch (mode) {
    case PAGE_CUR_GE:
      page_mode = PAGE_CUR_L;
      break;
    case PAGE_CUR_G:
      page_mode = PAGE_CUR_LE;
      break;
    default:
      page_mode = mode;
      break;
  }

  // 循环、逐层的查找，直至达到传入的层数 level，一般是0（即叶子节点） 此处的分析忽略Spatial index的部分
search_loop:
  fetch = cursor->m_fetch_mode;
  rw_latch = RW_NO_LATCH;
  rtree_parent_modified = false;

retry_page_get:
  tree_savepoints[n_blocks] = mtr_set_savepoint(mtr);
  block =
      buf_page_get_gen(page_id, page_size, rw_latch,
                       (height == ULINT_UNDEFINED ? info->root_guess : nullptr),
                       fetch, {file, line}, mtr);

  tree_blocks[n_blocks] = block;

  if (block == nullptr) {
     // 当block为null时，尝试change buffer操作
    switch (btr_op) {
      case BTR_INSERT_OP:
      case BTR_INSERT_IGNORE_UNIQUE_OP:

        if (ibuf_insert(IBUF_OP_INSERT, tuple, index, page_id, page_size,
                        cursor->thr)) {
          cursor->flag = BTR_CUR_INSERT_TO_IBUF;

          goto func_exit;
        }
        break;

      case BTR_DELMARK_OP:

        if (ibuf_insert(IBUF_OP_DELETE_MARK, tuple, index, page_id, page_size,
                        cursor->thr)) {
          cursor->flag = BTR_CUR_DEL_MARK_IBUF;

          goto func_exit;
        }

        break;

      case BTR_DELETE_OP:

        if (!row_purge_poss_sec(cursor->purge_node, index, tuple)) {
          /* The record cannot be purged yet. */
          cursor->flag = BTR_CUR_DELETE_REF;
        } else if (ibuf_insert(IBUF_OP_DELETE, tuple, index, page_id, page_size,
                               cursor->thr)) {
          /* The purge was buffered. */
          cursor->flag = BTR_CUR_DELETE_IBUF;
        } else {
          /* The purge could not be buffered. */
          buf_pool_watch_unset(page_id);
          break;
        }

        buf_pool_watch_unset(page_id);
        goto func_exit;

      default:
        ut_error;
    }

    // 操作change buffer没有成功，则更新fetch mode为从disk中获取该page，然后再次获取该page

    fetch = cursor->m_fetch_mode;

    goto retry_page_get;
  }

  //如果是往前搜索，则获取其左兄弟page，并对其加latch
  if (retrying_for_search_prev && height != 0) {
    /* also latch left sibling */
    page_no_t left_page_no;
    buf_block_t *get_block;

    rw_latch = upper_rw_latch;

    rw_lock_s_lock(&block->lock, UT_LOCATION_HERE);
    left_page_no = btr_page_get_prev(buf_block_get_frame(block), mtr);
    rw_lock_s_unlock(&block->lock);

    if (left_page_no != FIL_NULL) {

      prev_tree_savepoints[prev_n_blocks] = mtr_set_savepoint(mtr);
      get_block =
          buf_page_get_gen(page_id_t(page_id.space(), left_page_no), page_size,
                           rw_latch, nullptr, fetch, {file, line}, mtr);
      prev_tree_blocks[prev_n_blocks] = get_block;
      prev_n_blocks++;

      /* BTR_MODIFY_TREE doesn't update prev/next_page_no,
      without their parent page's lock. So, not needed to
      retry here, because we have the parent page's lock. */
    }

    /* release RW_NO_LATCH page and lock with RW_S_LATCH */
    mtr_release_block_at_savepoint(mtr, tree_savepoints[n_blocks],
                                   tree_blocks[n_blocks]);

    tree_savepoints[n_blocks] = mtr_set_savepoint(mtr);
    block = buf_page_get_gen(page_id, page_size, rw_latch, nullptr, fetch,
                             {file, line}, mtr);
    tree_blocks[n_blocks] = block;
  }

  // 当达到leaf层时.
  if (height == 0) {
    //1. 先对叶子加latch
    if (rw_latch == RW_NO_LATCH) {
      latch_leaves = btr_cur_latch_leaves(block, page_id, page_size, latch_mode,
                                          cursor, mtr);
    }

    //2. 释放mtr中index latch 和上层中的blocks
    switch (latch_mode) {
      case BTR_MODIFY_TREE:
      case BTR_CONT_MODIFY_TREE:
      case BTR_CONT_SEARCH_TREE:
        break;
      default:
        if (!s_latch_by_caller && !srv_read_only_mode && !modify_external) {
          /* Release the tree s-latch */
          /* NOTE: BTR_MODIFY_EXTERNAL
          needs to keep tree sx-latch */
          mtr_release_s_latch_at_savepoint(mtr, savepoint,
                                           dict_index_get_lock(index));
        }

        /* release upper blocks */
        if (retrying_for_search_prev) {
          for (; prev_n_releases < prev_n_blocks; prev_n_releases++) {
            mtr_release_block_at_savepoint(
                mtr, prev_tree_savepoints[prev_n_releases],
                prev_tree_blocks[prev_n_releases]);
          }
        }

        for (; n_releases < n_blocks; n_releases++) {
          if (n_releases == 0 && modify_external) {
            /* keep latch of root page */
            continue;
          }

          mtr_release_block_at_savepoint(mtr, tree_savepoints[n_releases],
                                         tree_blocks[n_releases]);
        }
    }

    page_mode = mode;
  }

  if (dict_index_is_spatial(index) && page_mode >= PAGE_CUR_CONTAIN) {
    //空间索引...
  } else if (height == 0 && btr_search_enabled &&
             !dict_index_is_spatial(index)) {
    //AHI 索引处理
    page_cur_search_with_match_bytes(block, index, tuple, page_mode, &up_match,
                                     &up_bytes, &low_match, &low_bytes,
                                     page_cursor);
  } else {
    
    up_bytes = low_bytes = 0;
    //在索引页中中查找对于指定的Tuple(二分查找),并将结果rec 保存到 page_cursor中。
    page_cur_search_with_match(block, index, tuple, page_mode, &up_match,
                               &low_match, page_cursor,
                               need_path ? cursor->rtr_info : nullptr);
  }


  if (level != height) {
    const rec_t *node_ptr;

    height--;

    //如果没有到达指定层，此时的page_cursor保存的是下层节点的索引页page_node
    node_ptr = page_cur_get_rec(page_cursor);

    offsets = rec_get_offsets(node_ptr, index, offsets, ULINT_UNDEFINED,
                              UT_LOCATION_HERE, &heap);

     // 可能导致SMO，重置index root page为search page，重新开始循环
    if (latch_mode == BTR_MODIFY_TREE &&
        btr_cur_need_opposite_intention(page, lock_intention, node_ptr)) {
    need_opposite_intention:

      if (n_releases > 0) {
        /* release root block */
        mtr_release_block_at_savepoint(mtr, tree_savepoints[0], tree_blocks[0]);
      }

      /* release all blocks */
      for (; n_releases <= n_blocks; n_releases++) {
        mtr_release_block_at_savepoint(mtr, tree_savepoints[n_releases],
                                       tree_blocks[n_releases]);
      }

      lock_intention = BTR_INTENTION_BOTH;

      page_id.reset(space, dict_index_get_page(index));
      up_match = 0;
      low_match = 0;
      height = ULINT_UNDEFINED;

      n_blocks = 0;
      n_releases = 0;

      goto search_loop;
    }

    //如果页面中的第一条记录或最后一条记录与要修改的键值相同,可能会选择另一个页面。因此，为了避免因阻塞另一个具有相同键值的搜索操作而导致死锁，
    //父页面不应被释放。
    if (!detected_same_key_root && lock_intention == BTR_INTENTION_BOTH &&
        !dict_index_is_unique(index) && latch_mode == BTR_MODIFY_TREE &&
        (up_match >= rec_offs_n_fields(offsets) - 1 ||
         low_match >= rec_offs_n_fields(offsets) - 1)) {
      const rec_t *first_rec =
          page_rec_get_next_const(page_get_infimum_rec(page));
      ulint matched_fields;

      if (node_ptr == first_rec || page_rec_is_last(node_ptr, page)) {
        detected_same_key_root = true;
      } else {
        matched_fields = 0;

        offsets2 = rec_get_offsets(first_rec, index, offsets2, ULINT_UNDEFINED,
                                   UT_LOCATION_HERE, &heap);
        cmp_rec_rec_with_match(node_ptr, first_rec, offsets, offsets2, index,
                               page_is_spatial_non_leaf(first_rec, index),
                               false, &matched_fields);

        if (matched_fields >= rec_offs_n_fields(offsets) - 1) {
          detected_same_key_root = true;
        } else {
          const rec_t *last_rec;

          last_rec = page_rec_get_prev_const(page_get_supremum_rec(page));

          matched_fields = 0;

          offsets2 = rec_get_offsets(last_rec, index, offsets2, ULINT_UNDEFINED,
                                     UT_LOCATION_HERE, &heap);
          cmp_rec_rec_with_match(node_ptr, last_rec, offsets, offsets2, index,
                                 page_is_spatial_non_leaf(last_rec, index),
                                 false, &matched_fields);
          if (matched_fields >= rec_offs_n_fields(offsets) - 1) {
            detected_same_key_root = true;
          }
        }
      }
    }

    /* If the page might cause modify_tree,
    we should not release the parent page's lock. */
    if (!detected_same_key_root && latch_mode == BTR_MODIFY_TREE &&
        !btr_cur_will_modify_tree(index, page, lock_intention, node_ptr,
                                  node_ptr_max_size, page_size, mtr) &&
        !rtree_parent_modified) {

      /* we can release upper blocks */
      for (; n_releases < n_blocks; n_releases++) {
        if (n_releases == 0) {
          /* we should not release root page
          to pin to same block. */
          continue;
        }

        /* release unused blocks to unpin */
        mtr_release_block_at_savepoint(mtr, tree_savepoints[n_releases],
                                       tree_blocks[n_releases]);
      }
    }

    //需要修改时，则给root page加SX latch , 给路径中的其他节点加X latch
    if (height == level && latch_mode == BTR_MODIFY_TREE) {
      /* we should sx-latch root page, if released already.
      It contains seg_header. */
      if (n_releases > 0) {
        mtr_block_sx_latch_at_savepoint(mtr, tree_savepoints[0],
                                        tree_blocks[0]);
      }

      /* x-latch the branch blocks not released yet. */
      for (ulint i = n_releases; i <= n_blocks; i++) {
        mtr_block_x_latch_at_savepoint(mtr, tree_savepoints[i], tree_blocks[i]);
      }
    }

   //重置page_id为下层子节点page，然后进入下层查找
    page_id.reset(space, btr_node_ptr_get_child_page_no(node_ptr, offsets));

    n_blocks++;

    goto search_loop;
  } 

  // 找到对应rec位置，更新cursor的low_match up_match字段
  if (level != 0) {
    if (upper_rw_latch == RW_NO_LATCH) {
      /* latch the page */
      buf_block_t *child_block;

      if (latch_mode == BTR_CONT_MODIFY_TREE) {
        child_block = btr_block_get(page_id, page_size, RW_X_LATCH,
                                    UT_LOCATION_HERE, index, mtr);
      } else {
        ut_ad(latch_mode == BTR_CONT_SEARCH_TREE);
        child_block = btr_block_get(page_id, page_size, RW_SX_LATCH,
                                    UT_LOCATION_HERE, index, mtr);
      }

      btr_assert_not_corrupted(child_block, index);
    } else {
      ut_ad(mtr_memo_contains(mtr, block, upper_rw_latch));
      btr_assert_not_corrupted(block, index);

      if (s_latch_by_caller) {
        ut_ad(latch_mode == BTR_SEARCH_TREE);
        /* to exclude modifying tree operations
        should sx-latch the index. */
        ut_ad(mtr_memo_contains(mtr, dict_index_get_lock(index),
                                MTR_MEMO_SX_LOCK));
        /* because has sx-latch of index,
        can release upper blocks. */
        for (; n_releases < n_blocks; n_releases++) {
          mtr_release_block_at_savepoint(mtr, tree_savepoints[n_releases],
                                         tree_blocks[n_releases]);
        }
      }
    }

    if (page_mode <= PAGE_CUR_LE) {
      cursor->low_match = low_match;
      cursor->up_match = up_match;
    }
  } else {
    cursor->low_match = low_match;
    cursor->low_bytes = low_bytes;
    cursor->up_match = up_match;
    cursor->up_bytes = up_bytes;

    // 根据查询的结果，更新该index的ahi信息
    if (btr_search_enabled && !index->disable_ahi) {
      btr_search_info_update(index, cursor);
    }
  }

func_exit:

  //....
}
```

### 4.4.4 page_cur_search_with_match()

在一个数据页内“二分查找”，定位到 record

```c++
void page_cur_search_with_match(const buf_block_t *block,
                                const dict_index_t *index,
                                const dtuple_t *tuple, page_cur_mode_t mode,
                                ulint *iup_matched_fields,

                                ulint *ilow_matched_fields,

                                page_cur_t *cursor, rtr_info_t *rtr_info) {
 
 
  //二分查找
  while (up - low > 1) {
    mid = (low + up) / 2;
    slot = page_dir_get_nth_slot(page, mid);
    mid_rec = page_dir_slot_get_rec(slot);

    cur_matched_fields = std::min(low_matched_fields, up_matched_fields);

    auto offsets = get_mid_rec_offsets();

    cmp = tuple->compare(mid_rec, index, offsets, &cur_matched_fields);

    if (cmp > 0) {
    low_slot_match:
      low = mid;
      low_matched_fields = cur_matched_fields;

    } else if (cmp) {
#ifdef PAGE_CUR_LE_OR_EXTENDS
      if (mode == PAGE_CUR_LE_OR_EXTENDS &&
          page_cur_rec_field_extends(tuple, mid_rec, offsets,
                                     cur_matched_fields, index)) {
        goto low_slot_match;
      }
#endif /* PAGE_CUR_LE_OR_EXTENDS */
    up_slot_match:
      up = mid;
      up_matched_fields = cur_matched_fields;

    } else if (mode == PAGE_CUR_G || mode == PAGE_CUR_LE
#ifdef PAGE_CUR_LE_OR_EXTENDS
               || mode == PAGE_CUR_LE_OR_EXTENDS
#endif /* PAGE_CUR_LE_OR_EXTENDS */
    ) {
      goto low_slot_match;
    } else {
      goto up_slot_match;
    }
  }

  slot = page_dir_get_nth_slot(page, low);
  low_rec = page_dir_slot_get_rec(slot);
  slot = page_dir_get_nth_slot(page, up);
  up_rec = page_dir_slot_get_rec(slot);

  /* Perform linear search until the upper and lower records come to
  distance 1 of each other. */

  while (page_rec_get_next_const(low_rec) != up_rec) {
    mid_rec = page_rec_get_next_const(low_rec);

    cur_matched_fields = std::min(low_matched_fields, up_matched_fields);

    auto offsets = get_mid_rec_offsets();

    cmp = tuple->compare(mid_rec, index, offsets, &cur_matched_fields);

    if (cmp > 0) {
    low_rec_match:
      low_rec = mid_rec;
      low_matched_fields = cur_matched_fields;

    } else if (cmp) {
#ifdef PAGE_CUR_LE_OR_EXTENDS
      if (mode == PAGE_CUR_LE_OR_EXTENDS &&
          page_cur_rec_field_extends(tuple, mid_rec, offsets,
                                     cur_matched_fields, index)) {
        goto low_rec_match;
      }
#endif /* PAGE_CUR_LE_OR_EXTENDS */
    up_rec_match:
      up_rec = mid_rec;
      up_matched_fields = cur_matched_fields;
    } else if (mode == PAGE_CUR_G || mode == PAGE_CUR_LE
#ifdef PAGE_CUR_LE_OR_EXTENDS
               || mode == PAGE_CUR_LE_OR_EXTENDS
#endif /* PAGE_CUR_LE_OR_EXTENDS */
    ) {
      if (!cmp && !cur_matched_fields) {
#ifdef UNIV_DEBUG
        mtr_t mtr;
        mtr_start(&mtr);

        /* We got a match, but cur_matched_fields is
        0, it must have REC_INFO_MIN_REC_FLAG */
        ulint rec_info = rec_get_info_bits(mid_rec, rec_offs_comp(offsets));
        ut_ad(rec_info & REC_INFO_MIN_REC_FLAG);
        ut_ad(btr_page_get_prev(page, &mtr) == FIL_NULL);
        mtr_commit(&mtr);
#endif

        cur_matched_fields = dtuple_get_n_fields_cmp(tuple);
      }

      goto low_rec_match;
    } else {
      goto up_rec_match;
    }
  }

  if (mode <= PAGE_CUR_GE) {
    page_cur_position(up_rec, block, cursor);
  } else {
    page_cur_position(low_rec, block, cursor);
  }

  *iup_matched_fields = up_matched_fields;
  *ilow_matched_fields = low_matched_fields;
  if (UNIV_LIKELY_NULL(heap)) {
    mem_heap_free(heap);
  }
}
```



## 4.5 索引分裂

分裂的方式有两种：

- **50% - 50%算法**：将旧页50%的数据量移动到新页
- **0% - 100%算法**：不移动旧页任何的数据，只将引起分裂的记录插入到新页  （每个 page 上记录上次插入位置 （PAGE_LAST_INSERT），以此判断本次插入是否递增或者递减，如果判定为顺序插入，就在当前插入点进行分裂）

<img src="https://picx.zhimg.com/v2-a3a87e43c3d91f01a7a9ff242e4611c9_1440w.jpg" alt="img" style="zoom:50%;" />

`数据页的分裂函数 btr_page_split_and_insert()

```C++
rec_t *btr_page_split_and_insert(
    uint32_t flags,        /*!< in: undo logging and locking flags */
    btr_cur_t *cursor,     /*!< in: cursor at which to insert; when the
                           function returns, the cursor is positioned
                           on the predecessor of the inserted record */
    ulint **offsets,       /*!< out: offsets on inserted record */
    mem_heap_t **heap,     /*!< in/out: pointer to memory heap, or NULL */
    const dtuple_t *tuple, /*!< in: tuple to insert */
    mtr_t *mtr)            /*!< in: mtr */
{
func_start:

  /* try to insert to the next page if possible before split */
  rec =
      btr_insert_into_right_sibling(flags, cursor, offsets, *heap, tuple, mtr);

  if (rec != nullptr) {
    return (rec);
  }

  page_no = block->page.id.page_no();

  /* 1. 从要分裂的 page 中, 找到要分裂的 record*/
  insert_left = false;

  if (n_iterations > 0) {
    //1.1 如果该数据页已经分裂一次（n_iterations），仍无法插入成功，则继续分裂
    direction = FSP_UP;
    hint_page_no = page_no + 1;
    split_rec = btr_page_get_split_rec(cursor, tuple);

    if (split_rec == nullptr) {
      insert_left =
          btr_page_tuple_smaller(cursor, tuple, offsets, n_uniq, heap);
    }
  } else if (btr_page_get_split_rec_to_right(cursor, &split_rec)) {
    // 向右分裂
    direction = FSP_UP;
    hint_page_no = page_no + 1;

  } else if (btr_page_get_split_rec_to_left(cursor, &split_rec)) {
    // 向左分裂
    direction = FSP_DOWN;
    hint_page_no = page_no - 1;
    ut_ad(split_rec);
  } else {
    //不是顺序插入的话，50%-50%算法向右分裂
    direction = FSP_UP;
    hint_page_no = page_no + 1;

    /* If there is only one record in the index page, we
    can't split the node in the middle by default. We need
    to determine whether the new record will be inserted
    to the left or right. */

    if (page_get_n_recs(page) > 1) {
      split_rec = page_get_middle_rec(page);
    } else if (btr_page_tuple_smaller(cursor, tuple, offsets, n_uniq, heap)) {
      split_rec = page_rec_get_next(page_get_infimum_rec(page));
    } else {
      split_rec = nullptr;
    }
  }

  /* 2.  分配一个新的 index page*/
  new_block = btr_page_alloc(cursor->index, hint_page_no, direction,
                             btr_page_get_level(page), mtr, mtr);

  /* New page could not be allocated */
  if (!new_block) {
    return nullptr;
  }

  new_page = buf_block_get_frame(new_block);
  new_page_zip = buf_block_get_page_zip(new_block);
  btr_page_create(new_block, new_page_zip, cursor->index,
                  btr_page_get_level(page), mtr);

  /* 3. 分别计算 page, 和 new page 的边界 record */

  if (split_rec) {
    first_rec = move_limit = split_rec;

    *offsets = rec_get_offsets(split_rec, cursor->index, *offsets, n_uniq,
                               UT_LOCATION_HERE, heap);

    insert_left = cmp_dtuple_rec(tuple, split_rec, cursor->index, *offsets) < 0;

    if (!insert_left && new_page_zip && n_iterations > 0) {
      /* If a compressed page has already been split,
      avoid further splits by inserting the record
      to an empty page. */
      split_rec = nullptr;
      goto insert_empty;
    }
  } else if (insert_left) {
    ut_a(n_iterations > 0);
    first_rec = page_rec_get_next(page_get_infimum_rec(page));
    move_limit = page_rec_get_next(btr_cur_get_rec(cursor));
  } else {
  insert_empty:
    ut_ad(!split_rec);
    ut_ad(!insert_left);
    buf = ut::new_arr_withkey<byte>(
        UT_NEW_THIS_FILE_PSI_KEY,
        ut::Count{rec_get_converted_size(cursor->index, tuple)});

    first_rec = rec_convert_dtuple_to_rec(buf, cursor->index, tuple);
    move_limit = page_rec_get_next(btr_cur_get_rec(cursor));
  }

  /* 4. 在父节点添加新的 index page 的 node ptr record（索引项），如果父节点没有足够的空间, 那么就触发父节点的分裂操作 */

  btr_attach_half_pages(flags, cursor->index, block, first_rec, new_block,
                        direction, mtr);

  /* If the split is made on the leaf level and the insert will fit
  on the appropriate half-page, we may release the tree x-latch.
  We can then move the records after releasing the tree latch,
  thus reducing the tree latch contention. */

  if (split_rec) {
    insert_will_fit =
        !new_page_zip &&
        btr_page_insert_fits(cursor, split_rec, offsets, tuple, heap);
  } else {
    if (!insert_left) {
      ut::delete_arr(buf);
      buf = nullptr;
    }

    insert_will_fit =
        !new_page_zip &&
        btr_page_insert_fits(cursor, nullptr, offsets, tuple, heap);
  }

  if (!srv_read_only_mode && !cursor->index->table->is_intrinsic() &&
      insert_will_fit && page_is_leaf(page) &&
      !dict_index_is_online_ddl(cursor->index)) {
    mtr->memo_release(dict_index_get_lock(cursor->index),
                      MTR_MEMO_X_LOCK | MTR_MEMO_SX_LOCK);

    /* NOTE: We cannot release root block latch here, because it
    has segment header and already modified in most of cases.*/
  }

  /* 5.  逐个的将记录从旧页拷贝到新页 */
  if (direction == FSP_DOWN) {
    /*          fputs("Split left\n", stderr); */

    if (false
        // 5.1 把旧页的记录逐个拷贝到新页
        || !page_move_rec_list_start(new_block, block, move_limit,
                                     cursor->index, mtr)) {

      page_zip_copy_recs(new_page_zip, new_page, page_zip, page, cursor->index,
                         mtr);
      
      page_delete_rec_list_end(move_limit - page + new_page, new_block,
                               cursor->index, ULINT_UNDEFINED, ULINT_UNDEFINED,
                               mtr);

      /* Update the lock table and possible hash index. */

      if (!dict_table_is_locking_disabled(cursor->index->table)) {
        lock_move_rec_list_start(new_block, block, move_limit,
                                 new_page + PAGE_NEW_INFIMUM);
      }

      btr_search_move_or_delete_hash_entries(new_block, block, cursor->index);

      // 5.2 再把旧页中的记录删除

      page_delete_rec_list_start(move_limit, block, cursor->index, mtr);
    }

    left_block = new_block;
    right_block = block;

  } else {
    /*          fputs("Split right\n", stderr); */

    if (false
#ifdef UNIV_ZIP_COPY
        || page_zip
#endif /* UNIV_ZIP_COPY */
        || !page_move_rec_list_end(new_block, block, move_limit, cursor->index,
                                   mtr)) {
      /* For some reason, compressing new_page failed,
      even though it should contain fewer records than
      the original page.  Copy the page byte for byte
      and then delete the records from both pages
      as appropriate.  Deleting will always succeed. */
      ut_a(new_page_zip);

      page_zip_copy_recs(new_page_zip, new_page, page_zip, page, cursor->index,
                         mtr);
      page_delete_rec_list_start(move_limit - page + new_page, new_block,
                                 cursor->index, mtr);

      /* Update the lock table and possible hash index. */
      if (!dict_table_is_locking_disabled(cursor->index->table)) {
        lock_move_rec_list_end(new_block, block, move_limit);
      }

      ut_ad(!dict_index_is_spatial(index));

      btr_search_move_or_delete_hash_entries(new_block, block, cursor->index);

      /* Delete the records from the source page. */

      page_delete_rec_list_end(move_limit, block, cursor->index,
                               ULINT_UNDEFINED, ULINT_UNDEFINED, mtr);
    }

    left_block = block;
    right_block = new_block;

    if (!dict_table_is_locking_disabled(cursor->index->table)) {
      lock_update_split_right(right_block, left_block);
    }
  }

  /* At this point, split_rec, move_limit and first_rec may point
  to garbage on the old page. */

  /* 6. 将当前索引页上的部分 record 移动到新的索引页 */

  if (insert_left) {
    insert_block = left_block;
  } else {
    insert_block = right_block;
  }

  /* 7. SMO 操作已经结束, 计算本次 insert 要插入的 page 位置 */
  page_cursor = btr_cur_get_page_cur(cursor);

  page_cur_search(insert_block, cursor->index, tuple, page_cursor);

  rec = page_cur_tuple_insert(page_cursor, tuple, cursor->index, offsets, heap,
                              mtr);

  if (rec != nullptr) {
    goto func_exit;
  }

  /* 8. 进行 insert 操作, 如果insert 失败, 通过 re-orgination page 重新尝试插入. */

  if (page_cur_get_page_zip(page_cursor) ||
      !btr_page_reorganize(page_cursor, cursor->index, mtr)) {
    goto insert_failed;
  }

  rec = page_cur_tuple_insert(page_cursor, tuple, cursor->index, offsets, heap,
                              mtr);

  if (rec == nullptr) {
    /* The insert did not fit on the page: loop back to the
    start of the function for a new split */
  insert_failed:
    /* We play safe and reset the free bits for new_page */
    if (!cursor->index->is_clustered() &&
        !cursor->index->table->is_temporary()) {
      ibuf_reset_free_bits(new_block);
      ibuf_reset_free_bits(block);
    }

    n_iterations++;
    ut_ad(n_iterations < 2 || buf_block_get_page_zip(insert_block));
    ut_ad(!insert_will_fit);

    goto func_start;
  }

func_exit:
  /* Insert fit on the page: update the free bits for the
  left and right pages in the same mtr */

  if (!cursor->index->is_clustered() && !cursor->index->table->is_temporary() &&
      page_is_leaf(page)) {
    ibuf_update_free_bits_for_two_pages_low(left_block, right_block, mtr);
  }

  MONITOR_INC(MONITOR_INDEX_SPLIT);

  ut_ad(page_validate(buf_block_get_frame(left_block), cursor->index));
  ut_ad(page_validate(buf_block_get_frame(right_block), cursor->index));

  ut_ad(!rec || rec_offs_validate(rec, cursor->index, *offsets));
  return (rec);
}

```

## 4.6 索引update

InnoDB中对B+Tree的修改、插入以及删除操作都会存在乐观和悲观两个版本

乐观版本假设本次操作不会导致树结构的变化，因此持有较轻量的锁，如果失败，那么就获取更重的锁，再通过悲观版本来完成变更。这里得修改包括对非Key Filed的修改，也包括对Delete Mark的修改，一次Update的过程如下：

- **btr_cur_optimistic_update**会比较要修改的Record的老值和新值占用的空间大小，

  1. 如果新值更小，那么简单的通过**btr_update_in_place**在当前位置直接更新，并接受Record变小带来的碎片。

  2. 如果新值需要的空间更大，那么就需要先在Page上删除老的Record，再插入新的Record，这时会先计算删除后是否有空间插入新的的Record，如果能，那么通过**page_cur_delete_rec**删除，之后再通过**btr_cur_insert_if_poossible**再次插入就好。

- 但如果Page上无法放下新值，那么就需要返回失败，并在加更重的锁之后通过**btr_cur_pessimistic_update**来完成，这里先page_cur_delete_rec完成删除，然后通过**btr_cur_pessimistic_insert**来做悲观插入，其中可能需要先完成B+Tree的节点分裂甚至是树层数的增高。

```c++
dberr_t btr_cur_optimistic_update(ulint flags, btr_cur_t *cursor,
                                  ulint **offsets, mem_heap_t **heap,
                                  const upd_t *update, ulint cmpl_info,
                                  que_thr_t *thr, trx_id_t trx_id, mtr_t *mtr) {


  page_cursor = btr_cur_get_page_cur(cursor);

  /*构建新的entry，将upd_struct中的记录更新到dtuple_t中 */
  new_entry = row_rec_to_index_entry(rec, index, *offsets, *heap);

  row_upd_index_replace_new_col_vals_index_pos(new_entry, index, update, false,
                                               *heap);

  old_rec_size = rec_offs_size(*offsets);
  new_rec_size = rec_get_converted_size(index, new_entry);

  page_zip = buf_block_get_page_zip(block);


  if (page_zip) {
    //如果是压缩表，调用btr_cur_update_alloc_zip查看有没有空闲mlog空间，如果没有，则返回DB_OVERFLOW错误
    if (!btr_cur_update_alloc_zip(page_zip, page_cursor, index, *offsets,
                                  new_rec_size, true, mtr)) {
      return (DB_ZIP_OVERFLOW);
    }

    rec = page_cur_get_rec(page_cursor);
  }

  //不能大于16K
  if (new_rec_size >= REC_MAX_DATA_SIZE) {
    err = DB_OVERFLOW;

    goto func_exit;
  }

  /* 新记录大于非压缩页空闲空间的一半，返回DB_OVERFLOW. */
  if (UNIV_UNLIKELY(new_rec_size >=
                    (page_get_free_space_of_empty(page_is_comp(page)) / 2))) {
    /* We may need to update the IBUF_BITMAP_FREE
    bits after a reorganize that was done in
    btr_cur_update_alloc_zip(). */
    err = DB_OVERFLOW;
    goto func_exit;
  }

  //.更新后非压缩Page上的数据小于BTR_CUR_PAGE_COMPRESS_LIMIT，也就是8k时，返回DB_UNDERFLOW错误，表明该page太空了，随后上层逻辑会尝试将其中的数据转移到邻居节点
  if (UNIV_UNLIKELY(page_get_data_size(page) - old_rec_size + new_rec_size <
                    BTR_CUR_PAGE_COMPRESS_LIMIT(index))) {
    err = DB_UNDERFLOW;
    goto func_exit;
  }


  //调用btr_cur_upd_lock_and_undo检查锁并记录undo
  err = btr_cur_upd_lock_and_undo(flags, cursor, *offsets, update, cmpl_info,
                                  thr, mtr, &roll_ptr);
  if (err != DB_SUCCESS) {
    goto func_exit;
  }

  //从adaptive hash index中删除记录
  btr_search_update_hash_on_delete(cursor);
  //删除当前记录(page_cur_delete_rec)
  page_cur_delete_rec(page_cursor, index, *offsets, mtr);
  //移动page_cursor到前一个记录(page_cur_move_to_prev)
  page_cur_move_to_prev(page_cursor);

  //更新记录的roll_ptr及trx_id
  if (!(flags & BTR_KEEP_SYS_FLAG) && !index->table->is_intrinsic()) {
    row_upd_index_entry_sys_field(new_entry, index, DATA_ROLL_PTR, roll_ptr);
    row_upd_index_entry_sys_field(new_entry, index, DATA_TRX_ID, trx_id);
  }

  //插入new_entry记录
  rec = btr_cur_insert_if_possible(cursor, new_entry, offsets, heap, mtr);
  ut_a(rec); /* <- We calculated above the insert would fit */

  /* Restore the old explicit lock state on the record */
  if (!dict_table_is_locking_disabled(index->table)) {
    lock_rec_restore_from_page_infimum(block, rec, block);
  }

  page_cur_move_to_next(page_cursor);
  ut_ad(err == DB_SUCCESS);

func_exit:
  if (!(flags & BTR_KEEP_IBUF_BITMAP) && !index->is_clustered()) {
    /* Update the free bits in the insert buffer. */
    if (page_zip) {
      ibuf_update_free_bits_zip(block, mtr);
    } else {
      ibuf_update_free_bits_low(block, max_ins_size, mtr);
    }
  }

  if (err != DB_SUCCESS) {
    /* prefetch siblings of the leaf for the pessimistic
    operation. */
    btr_cur_prefetch_siblings(block);
  }

  return (err);
}

```

```c++
dberr_t btr_cur_pessimistic_update(ulint flags, btr_cur_t *cursor,
                                   ulint **offsets, mem_heap_t **offsets_heap,
                                   mem_heap_t *entry_heap, big_rec_t **big_rec,
                                   upd_t *update, ulint cmpl_info,
                                   que_thr_t *thr, trx_id_t trx_id,
                                   undo_no_t undo_no, mtr_t *mtr,
                                   btr_pcur_t *pcur) {
 
  rec = btr_cur_get_rec(cursor);

  *offsets = rec_get_offsets(rec, index, *offsets, ULINT_UNDEFINED,
                             UT_LOCATION_HERE, offsets_heap);
  //同乐观一样，先构建新的entry，并将upd_struct中的记录更新到dtuple_t中
  dtuple_t *new_entry =
      row_rec_to_index_entry(rec, index, *offsets, entry_heap);

  row_upd_index_replace_new_col_vals_index_pos(new_entry, index, update, false,
                                               entry_heap);

  //调用btr_cur_upd_lock_and_undo检查锁并记录undo
  err = btr_cur_upd_lock_and_undo(flags, cursor, *offsets, update, cmpl_info,
                                  thr, mtr, &roll_ptr);
  if (err != DB_SUCCESS) {
    goto err_exit;
  }

  if (optim_err == DB_OVERFLOW) {
    // 提前锁定file space，防止死锁
    fil_space_t *space = fil_space_get(index->space);
    mtr_x_lock_space(space, mtr);
  }

  if (optim_err == DB_OVERFLOW) {
    //为索引树的文件段预留足够的空间

    ulint n_extents = cursor->tree_height / 16 + 3;

    if (!fsp_reserve_free_extents(
            &n_reserved, index->space, n_extents,
            flags & BTR_NO_UNDO_LOG_FLAG ? FSP_CLEANING : FSP_NORMAL, mtr)) {
      err = DB_OUT_OF_FILE_SPACE;
      goto err_exit;
    }
  }

  //更新记录的roll_ptr及trx_id
  if (!(flags & BTR_KEEP_SYS_FLAG) && !index->table->is_intrinsic()) {
    row_upd_index_entry_sys_field(new_entry, index, DATA_ROLL_PTR, roll_ptr);
    row_upd_index_entry_sys_field(new_entry, index, DATA_TRX_ID, trx_id);
  }

  if (!page_zip) {
    max_ins_size = page_get_max_insert_size_after_reorganize(page, 1);
  }

  btr_search_update_hash_on_delete(cursor);

  page_cursor = btr_cur_get_page_cur(cursor);

  page_cur_delete_rec(page_cursor, index, *offsets, mtr);

  page_cur_move_to_prev(page_cursor);

  //乐观插入
  rec =
      btr_cur_insert_if_possible(cursor, new_entry, offsets, offsets_heap, mtr);

  if (rec) {
    //乐观插入成功...
    err = DB_SUCCESS;
    goto return_after_reservations;
  } else {
    // 空间不足，插入失败...
  }

  if (big_rec_vec != nullptr && !index->table->is_intrinsic()) {
    // btr_cur_pessimistic_insert()会释放index的sx锁，在此先再次加锁保证持有index锁，

    mtr_sx_lock(dict_index_get_lock(index), mtr, UT_LOCATION_HERE);
  }

  /* Was the record to be updated positioned as the first user
  record on its page? */
  was_first = page_cur_is_before_first(page_cursor);

  //悲观插入
  err = btr_cur_pessimistic_insert(
      BTR_NO_UNDO_LOG_FLAG | BTR_NO_LOCKING_FLAG | BTR_KEEP_SYS_FLAG, cursor,
      offsets, offsets_heap, new_entry, &rec, &dummy_big_rec, nullptr, mtr);
  
  page_cursor->rec = rec;

 
    //...
  

return_after_reservations:

  //清理环境、传递big_rec_vec溢出列对象...
  if (n_reserved > 0) {
    fil_space_release_free_extents(index->space, n_reserved);
  }

  *big_rec = big_rec_vec;

  return err;
}

```



```c++
  ->>ha_innobase::update_row
    ... (检查log空间、row update node)
      ->>row_upd_clust_step (启动mtr)
        ->>btr_pcur_restore_position (乐观获取leaf节点x-latch)
        ->>row_upd_clust_rec
          ->>btr_cur_optimistic_update (存在溢出列，乐观更新失败，返回DB_OVERFLOW)
            ->>btr_cur_prefetch_siblings
          ->>mtr->commit，mtr->start(释放获取的mtr资源，重启mtr)
          ->>btr_pcur_restore_position (进入悲观模式，重新定位cursor)
            ->>btr_cur_search_to_nth_level(获取index的sx-latch，从root搜索至目标叶子结点，最终会施加目标节点、父节点、左右节点的x-latch)
          ->>btr_cur_pessimistic_update 
            ->>btr_cur_optimistic_update (同上失败)
            ->>row_rec_to_index_entry (获得index entry，不包括溢出列)
            ->>row_upd_index_replace_new_col_vals_index_pos (更新index entry)
              ->>row_upd_index_replace_new_col_val_func (更新对应列，此时更新的大字段会被完全copy到index entry，老的溢出列会被标记)
            ->>dtuple_convert_big_rec (构建溢出列对象)
            ->>btr_cur_upd_lock_and_undo (进行undo记录)
            ->>mtr_x_lock_space(space, mtr) (在锁定LOB page前锁定file space，避免死锁)
            ->>fsp_reserve_free_extents (预留文件空间)
            ... (锁处理、删除原index记录)
            ->>btr_cur_insert_if_possible (乐观插入)
            |乐观插入失败|->>btr_cur_pessimistic_insert (悲观插入)
            ->>unmark_extern_fields (标记溢出列)
            ->>fil_space_release_free_extents (释放预留空间)
          ->>btr_store_big_rec_extern_fields (存储溢出列)
            ->>InsertContext::check_redolog (重定位cursor、重启mtr，可见index列和off-page列并不是一个mtr)
            |遍历所有溢出列|... (检查是否可以部分更新)
              ->>lob::insert (将溢出列实际插入tablespace)
                ->>first_page_t::alloc (分配首lob页)
                ->>first_page_t::write、设定相关信息
                |有后续lob页|->>data_page_t::alloc、data_page_t::write、设定相关信息
              ->> ... (更新upd_field_t中的溢出列ref)
          ->>mtr->commit (提交mtr，释放index、page锁等资源)
          ->>dtuple_big_rec_free (清理溢出页内存)
        ... (清理工作)
  ->>ha_innobase::read_range_next
...

```





## 4.7 索引删除

删除操作只会对记录设置Delete Mark标记，而将真正的B+Tree上的记录删除推迟到后台Undo Purge中进行 （细节略）



## 4.8 undo寻的可见版本

```c++
|--row_search_mvcc()
|			|--Row_sel_get_clust_rec_for_mysql::operator()
|			|			|--row_sel_build_prev_vers_for_mysql()
|			|			|			|--row_vers_build_for_consistent_read() //构建版本一致性读
|			|			|			|			|-->//enter loop
|			|			|			|			|--trx_undo_prev_version_build() //通过undo找到一个版本
|			|			|			|			|--changes_visible()		//对当前版本判断可见性
|			|			|			|			|<--//exit loop
  
```



# 五：pg中blink-tree实现  

![img](https://i-blog.csdnimg.cn/blog_migrate/895c278f736b79522afca14929d81eb6.png)

1.基本的BTree 索引持久化形态是和 Heap 表基本一样（除了唯一的Meta page），每一个节点保存到一个page，节点内的key 已经 子节点保存的value都会作为index tuple 保存到该 page中。
2.Meta page 用来保存当前BTree 的元数据，也是索引page的第0页
3.Inner Node 内部节点，其index-tuple 中 仅保存key 以及指向子节点的指针
4.Leaf Node 叶子节点，是BTree 索引的最底层，其内部的 index-tuple 保存的是key 以及 指向 数据tuple的 tid。通过 tid 能够访问这个key 对应的实际数据。
5.每一个节点所在的page 内部最后有一部分 Special space空间，保存了当前节点或者说 index-page 的元数据，其是通过    	BTPageOpaqueData表示。主要保存这个 page 左右方向指针、page所在 BTree 层级、以及当前页面的状态（叶子节点/内部节点/根节点/删除页面…）

### 插入：

B树的插入都需要先搜索到目标叶节点，再判断是否进行分裂，如果发生分裂则需要产生新的结点，并分配旧结点内的元素，同时还要判断是否触发递归分裂。

分裂的条件不是依据 每一个节点内部 key的个数，而是节点所在page的大小，比如page 没有插入下一个tuple 的空间了  或者 页面可用不足25%（填充因子fill factor 控制的），则才会触发分裂。

```c
btinsert
    ->index_from_tuple          /* 生成索引元组*/
    ->_bt_doinsert              /* 执行插入 */
        ->_bt_mkscankey         /* 根据属性计算关键字 */
        ->_bt_search_insert     /* 根据关键字与插入模式找到目标叶节点(以栈的形式返回) */
        ->_bt_findinsertloc     /* 搜索可以插入的位置 */
            ->_bt_check_third_page      /* 判断页面中元素的数量是否超过1/3 */
            ->_bt_stepright             /* 在并发访问的情况下，当前结点可能会分裂，因为PG中只允许向右分裂，所以需要将右边页面也加入到栈中 */
        ->_bt_insertonpg        /* 将索引元组插入到目标页面 */
            ->_bt_split         /* 分裂入口 */
                ->_bt_findsplitloc      /* 搜索分裂的位置 */
            ->_bt_insert_parent         /* 分裂时需要在父节点中插入信息，同时开始递归判断是否要继续分裂 */
```

当分裂结点时会生成FindSplitData结构，用来记录寻找结点分裂位置时的相关信息：

```c
typedef struct
{
    /* context data for _bt_recsplitloc */
    Relation    rel;            /* index relation */
    Page        origpage;       /* page undergoing split */
    IndexTuple  newitem;        /* new item (cause of page split) */
    Size        newitemsz;      /* size of newitem (includes line pointer) */
    bool        is_leaf;        /* T if splitting a leaf page */
    bool        is_rightmost;   /* T if splitting rightmost page on level */
    OffsetNumber newitemoff;    /* where the new item is to be inserted */
    int         leftspace;      /* space available for items on left page */
    int         rightspace;     /* space available for items on right page */
    int         olddataitemstotal;  /* space taken by old items */
    Size        minfirstrightsz;    /* smallest firstright size */

    /* candidate split point data */
    int         maxsplits;      /* maximum number of splits */
    int         nsplits;        /* current number of splits */
    SplitPoint *splits;         /* all candidate split points for page */
    int         interval;       /* current range of acceptable split points */
} FindSplitData;
```

### 查找

btgettuple：得到扫描中下一个满足条件的索引元组。该函数在第一次调用时(执行第一次扫描时)，需要初始化关键字数组，用于确定扫描顺序。如果是第一次扫描，那么调用_bt_frist()函数获取扫描顺序的第一个元组，否则调用_bt_next()函数获取下一个元组。该函数的调用栈如下

```text
btgettuple
    ->if not initialize the array before
    	->_bt_start_array_keys // 初始化查询数组
    ->if first call for a scan
        ->_bt_first
    ->else
        ->_bt_next
```



### 删除

在PG中，删除B-Tree索引元组的函数主要有两个：

- btvacuumcleanup：寻找可以删除的页面；
- btbulkdelete：批量删除指向一个表元组集合所对应的所有索引元组。

出于效率考虑，PG中删除某个元组并不会立即删除对应的索引元组，有两种场景

1. **simple deletion**：它由 index scan 触发，因为 index scan 会先访问 index， 然后再访问 heap 表，所以在访问 heap 表后，可以将有  效性信息回馈给 index，并在 index 的无效版本上打上标记。后续在 page split 时，可以批量物理删除这些无效版本，以避免 split。对于非索引页上的更新，有HOT技术不会新增索引结构。
2. **vacuum：**当统计到删除和更新数量达到特定阈值时触发 vacuum。先扫描 heap 表数据并找到无效的 tuple，然后批量去 B-tree index 做物理删除。这里对 index 也是顺序扫描文件，从而提升读取吞吐量。

删除流程：

​                             p

​                            |

​                  A  <-> C <->B

1. 先找到要删除的节点 C, 加锁
2. 找到C的父节点P，加锁
3. 将C的downlink指针指向右兄弟B。同时删除B的downlink指针。这样无论左右兄弟都无须更新high key
4. 释放C 和 P的锁
5. 将C从节点A和B之间移除（加锁顺序：先释放 A 锁，再按照 A、C、B 从左到右的顺序加锁，代码_bt_unlink_halfedad_page()）



### 崩溃一致性保证

1.在每一层完成split的后，记录一条日志，最后再释放锁。

2.如果需要递归多层split的话，当完成一层后，会打上一个incomplete-split 标记，表明split未完成。



