# 一：概述

（1）Copy 方式

  这是InnoDB最早支持的创建索引的方式。

  实现原理：新建一个带有新索引的临时表，将原表数据全部拷贝到临时表，然后Rename，完成创建索引的操作。

  这个方式创建索引，创建过程中，原表是可读的。但是会消耗一倍的存储空间。

（2）Inplace方式
    是索引创建在原表上直接进行，不会拷贝临时表。Inplace方式创建索引，创建过程中，原表同样可读的，但是不可写。

   有以下场景：

- 重命名表。 mysql会重命名table对应的文件，并不会做copy数据的操作。（per_file_on_table 需要打开）
- 仅修改表的元数据的操作，包括： rename column，变更列的默认值，不改变数据类型存储空间的操作
- 重命名索引
- 添加或者删除一个二级索引

（3）Online方式
   InnoDB支持了所谓的Online方式创建索引。

​      实现原理：InnoDB的Online Add Index，首先是Inplace方式创建索引，无需使用临时表。在遍历聚簇索引，收集记录并插入到新索引。的过程中，原表记录可修改。而修改的记录保存在Row Log中。当聚簇索引遍历完毕，并全部插入到新索引之后，重放Row Log中的记录修改，使得新索引与聚簇索引记录达到一致状态。



# 二：主流程

分为三阶段：

1. Prepare 阶段：主要是准备好key columns 信息
2. 执行阶段：inplace 和 copy 执行不同的模块
3. commit 阶段：记录binlog 同时提交事物

```c++
|-->mysql_alter_table()
|		|-->mysql_prepare_alter_table() //prepare ddl , 准备好列以及key定义
|		|-->fill_alter_inplace_info() //填充 handler_flags
|		|-->mysql_inplace_alter_table() || copy模式逻辑处理

```

##  2.1 copy模式逻辑处理流程：

```c++
|		|--> upgrade_shared_lock() //先升级MDL_SHARED_NO_WRITE，允许读，但不允许update
|		|--> ha_create_table()			//创建临时表
|		|--> open_table_uncached()
|		|--> copy_data_between_tables()//拷贝数据 iterator->Read() -----> ha_write_row()
|		|--> close_all_tables_for_name()
|		|--> mysql_rename_table()  // old name --> backup name
|		|--> mysql_rename_table()  // tmp name --> old name
|		|--> quick_rm_table()  // backup name
|		|-->write_bin_log() 
|		|-->tdc_remove_table() //更新table_sharing
|		|-->trans_commit_stmt() //事务提交
```

## 2.2 inplace 处理流程

```c++
|-->mysql_inplace_alter_table()
|   |-->wait_while_table_is_used()
|		|		|-->upgrade_shared_lock(MDL_EXCLUSIVE) //MDL锁升级
|		|		|-->tdc_remove_table()			//从cache中删除未使用的table instances
|   |--> lock_tables()
|   |---------------------//调用engine层去处理
|   |--> //1. preapre 阶段
|   |--> ha_prepare_inplace_alter_table()
|   |--> table->mdl_ticket->downgrade_lock(MDL_SHARED_UPGRADABLE)  // MDL 锁降级为 MDL_SHARED_UPGRADABLE
|   |--> // 2. execute 阶段
|   |-->ha_inplace_alter_table()
|   |-->wait_while_table_is_used()
|   |		|-->upgrade_shared_lock(MDL_EXCLUSIVE) //在commit前 MDL锁升级
|   |   |-->tdc_remove_table()
|   |--> // 3.commit 阶段
|   |-->ha_commit_inplace_alter_table()
|   |-->close_all_tables_for_name()
|   |-->close_temporary_table()
|		|-->Table_impl::copy_triggers()
|   |-->thd->dd_client()->drop(table_def) //dd表删除旧表信息
|   |-->thd->dd_client()->store(altered_table_def)//dd 更新 新表信息
|   |-->write_bin_log()  // 记录 binlog
|   |-->trans_commit_stmt()  // 事务提交（在事务提交过程中会释放mdl锁）
```

![online_add_column](http://mysql.taobao.org/monthly/pic/202003/2020-03-03-hangfeng-online-add-column.png)

### 2.2.1 prepare 阶段

本阶段的主要目的是生成 InnoDB 层的 dict_table_t 对象，创建 IBD 文件，生成 B+tree

```c++
|-->ha_innobase::prepare_inplace_alter_table()
|		|-->ha_innobase::prepare_inplace_alter_table_impl()
|   |		|-->is_instant()//指定为instant ddl
|   |   |-->innobase_support_instant()//现仅支持rename column, add/drop column.如支持，则直接返回
|   |   |--> innobase_check_index_keys() //检查索引名是否可用，索引key是否有效
|   |   |-->ha_innobase_inplace_ctx() //构建handler_ctx对象，用于execute阶段
|   |   |-->prepare_inplace_alter_table_dict()//innodb层对数据字典操作
|   |   |		|-->1. trx_start_if_not_started_xa() //开启事务
|   |   |		|-->2. innobase_create_key_defs() //创建InnoDB存储引擎的索引定义对象 ddl::Index_defn
|   |   |		|-->3. row_mysql_lock_data_dictionary()  // dd表上RW_X_LATCH锁
|   |   |		|-->4. dict_stats_wait_bg_to_stop_using_table()//等待后台所有统计线程不再统计此表，可能会导致其他sql变慢
|   |   |		|-->5. online_retry_drop_dict_indexes() //从字典cache中删除索引
|   |   |		|-->//如果需要创建新的clustered index，此时需要临时表来进行重建表。否则直接创建对应索引
|   |   |		|-->6. dict_mem_create_temporary_tablename() //#sql-ibtableid-random_inc 
|   |   |		|-->7. dd_table_open_on_name(new_table_name) //打开新表
|   |   |		|-->8. dict_mem_table_create() // 创建dict_table_t对象（InnoDB 中的表） 
|   |   |		|-->9. dict_mem_table_add_col() //loop 为dict_table_t添加列信息
|   |   |		|-->10. row_create_table_for_mysql()
|   |   |		|		|-->10.1 dict_build_table_def() //构建表空间以及ibd文件
|   |   |		|		|		|-->dict_table_assign_new_id(&table->id, nullptr, nullptr) //获取新的table_id
|   |   |		|		|		|		|-->mach_read_from_8(dict_hdr + DICT_HDR_TABLE_ID)++ //table_id
|   |   |		|		|		|-->dict_build_tablespace_for_table()//实现构建表空间
|   |   |		|		|		|-->dict_hdr_get_new_id(nullptr, nullptr, &space) //获取新的space_id
|   |   |		|		|		|		|-->mtr_read_ulint(dict_hdr + DICT_HDR_MAX_SPACE_ID, MLOG_4BYTES, &mtr)++ //space_id
|   |   |		|		|		|-->fil_ibd_create() //创建ibd文件
|   |   |		|		|-->10.2 dict_table_add_system_columns() //添加系统列：DB_ROW_ID，DB_TRX_ID，DB_ROLL_PTR
|   |   |		|		|-->10.3 dict_table_add_to_cache() //把dict_table_t表信息加到字典cache中
|   |   |		|-->11. innobase_build_col_map() //构建col maps
|   |   |		|-->12. create_index()
|   |   |		|		|-->12.1 dict_mem_index_create() //构建dict_index_t对象
|   |   |		|		|-->12.2 dict_index_t::add_field() //dict_index_t添加col信息
|   |   |		|		|-->12.3 dict_build_index_def() //主要是获取index_id信息；
|   |   |		|		|		|-->mach_read_from_8(dict_hdr + DICT_HDR_INDEX_ID);
|   |   |		|		|-->12.4 dict_index_add_to_cache_w_vcol() //把dict_index_t信息加到字典cache中
|   |   |		|		|-->12.5 dict_create_index_tree_in_mem() //创建b+树
|   |   |		|		|		|-->btr_create()
|   |   |		|-->13.  row_log_allocate() //如果是online ddl,非new_clustered,就会分配row-log记录增量数据
|   |   |		|-->14. row_mysql_unlock_data_dictionary() //dd表释放锁
|   |   |		|-->15. dd_prepare_inplace_alter_table()
|   |   |		|		|-->dd_drop_tablespace(client, old_space_id) //删除旧表space_id
|   |   |		|		|-->dd_create_implicit_tablespace()
|   |   |		|		|		|-->dd_create_tablespace() //新增新表的space_id
```

### 2.2.2  execute 阶段

本阶段的目的是进行完整的数据写入， Inplace DDL 过程中 MDL 锁已经降级为 MDL_SHARED_UPGRADABLE（允许读写），因此数据写入分为两个部分：存量数据重建 + 增量数据写入。



#### 存量数据重建

可分为三个阶段：

1. parallel scan  扫描老表的主键数据（并行数innodb_parallel_read_threads ）
2. merge & sort 临时文件排序
3. build  构建索引

 其中2步骤也可以并行，其通过innodb_ddl_threads（默认值：4） 控制

```c++
ha_innobase::inplace_alter_table()
|-->ha_innobase::inplace_alter_table_impl()
|		|-->is_instant()     //instant ddl直接返回
|		|-->ctx=ha_alter_info->handler_ctx//prepare阶段ha_innobase_inplace_ctx()生成
|		|-->1. ddl::Context ddl //调用Context::Context()构造函数
|		|		|-->observer=ut::new_withkey<Flush_observer>(...) //构造flush observer来保证刷脏，因为bulk load关闭了redo
|		|		|-->trx_set_flush_observer() //observer赋值给trx
|		|-->2. Context::build()
|		|		|-->2.1 Loader::build_all() //index load
|		|		|		|-->2.1.1 Loader::prepare()//为每个索引创建builder对象并push_back到m_builders
|		|		|		|		|-->//loop, 遍历所有的索引
|		|		|		|		|-->m_builders.push_back(builder)
|		|		|		|		|-->//end loop  
|		|		|		|-------------------------//scan 阶段-----------------------------------------------------
|		|		|		|-->2.1.2 Loader::scan_and_build_indexes()
|		|		|		|		|-->i.  cursor=Cursor::create_cursor(m_ctx) //ctx创建Parallel_cursor
|		|		|		|		|-->ii. cursor->open() 	//do-nothing
|		|		|		|		|-->iii.innobase_rec_reset() //reset table->record[0]即row-buffer
|		|		|		|		|-->iv. cursor->scan(m_builders) //scan阶段 Parallel_cursor::scan()
|		|		|		|		|		|-->//loop
|		|		|		|		|		|-->iv.1 builder->init(*this, use_n_threads)//遍历m_builders中每个builder
|		|		|		|		|		|		|-->//当前状态机为 State::INIT ==> State::ADD  
|		|		|		|		|		|		|-->Context::scan_buffer_size()//均分参数innodb_ddl_buffer_size(1MB)用于key_buf
|		|		|		|		|		|		|-->key_buffer=ut::new_withkey<Key_sort_buffer>(...) //为每一个index创建key_buf
|		|		|		|		|		|		|-->thread_ctx=ut::new_withkey<Thread_ctx>(...)//为每一个索引创建n个ctx,并加入集合中
|		|		|		|		|		|		|-->m_btr_load=ut::new_withkey<Btree_load>(...) //skip_file_sort场景 
|		|		|		|		|		|		|-->set_next_state()//下一个状态 State::ADD
|		|		|		|		|		|-->iv.2 m_heaps.push_back()//为每个thread分配内存用来读取数据
|		|		|		|		|		|-->//end loop
|		|		|		|		|		|-->//同parallel scan的流程
|		|		|		|		|		|-->iv.3 Parallel_reader reader{n_threads}
                             Parallel_reader::Config config(FULL_SCAN, index())
                             reader.add_scan()
|		|		|		|		|		|-->iv.4 reader.run(n_threads) 
														...
|		|		|		|		|		|		|-->Parallel_reader::Ctx::traverse_recs()//遍历cluster-tree上rec
|		|		|		|		|		|		|-->err = m_scan_ctx->m_f(this)//在获取到rec后，调用回调函数
|		|		|		|		|		|		|-------//merge ---------------------------------------------------------
|		|		|		|		|		|		|-->Row::build() 
|		|		|		|		|		|		|		|-->row_build_w_add_vcol()  //根据rec->dtuple
|		|		|		|		|		|		|		|-->Context::handle_autoinc() //处理自增列场景
|		|		|		|		|		|		|-->bulk_inserter()	//把row拷贝到每一个builder中
|		|		|		|		|		|		|		|-->Builder::add_row()
|		|		|		|		|		|		|		|		|-->Builder::batch_add_row()//空间索引，not care
|		|		|		|		|		|		|		|		|-->Builder::bulk_add_row() //Btree索引
|		|		|		|		|		|		|		|		|		|-->Builder::add_to_key_buffer()//写入key-buffer
|		|		|		|		|		|		|		|		|		|		|-->Builder::copy_row()//拷贝row => m_key_buffer->m_dtuples
|		|		|		|		|		|		|		|		|		|		|		|-->return DB_OVERFLOW//如果key_buffer满了
|		|		|		|		|		|		|		|		|		|		|		|-->Builder::copy_columns()//深拷贝各列数据dfield_copy()
|		|		|		|		|		|		|		|		|		|-->case 1: return //not  DB_OVERFLOW
|		|		|		|		|		|		|		|		|		|-->case 2: Builder::key_buffer_sort() //DB_OVERFLOW
|		|		|		|		|		|		|		|		|		|		|-->merge_sort() //在key-buffer里排序
|		|		|		|		|		|		|		|		|		|-->case 3:Builder::insert_direct() //skip_file_sort,主键无需filesort
|		|		|		|		|		|		|		|		|		|		    -->Btree_load::build()//key_buffer里dtuples插入Btree
|		|		|		|		|		|		|		|		|		|		    -->key_buffer->clear()
|		|		|		|		|		|		|		|		|		|		    -->return DB_END_OF_INDEX
|		|		|		|		|		|		|		|		|		|-->create_file() or open_file() //二级索引，需要临时file排序
|		|		|		|		|		|		|		|		|		|		    -->key_buffer->serialize(io_buffer, persistor)//写入文件
|		|		|		|		|		|		|		|		|		|		    -->ddl::pwrite()  
|		|		|		|		|		|		|		|		|		|		    -->key_buffer->clear()
|		|		|		|		|		|		|		|		|		|		    -->return DB_END_OF_INDEX
|		|		|		|		|		|		|-------//end merge -------------------------------------------------
|		|		|		|		|		|-->iv.5 cleanup() //当thread结束后，清理每个thread中m_heaps
|		|		|		|		|-->v. cursor->finish() //do nothing
|		|		|		|-------------------------//end scan 阶段-----------------------------------------------------
|		|		|		|-------------------------//load 阶段---------------------------------------------------------
|		|		|		|-->2.1.3 Loader::load()
|		|		|		|		|-->//loop,遍历所有的 builder
|		|		|		|		|-->builder->set_next_state() //State::ADD ==> State::SETUP_SORT
|		|		|		|		|-->add_task(Task{builder}) // task和builder对应，跟索引个数对应
|		|		|		|		|-->//end loop
|		|		|		|		|-->-----------------//创建innodb_ddl_threads-1个线程执行执行sort-builder流程----------------
|		|		|		|		|-->threads.push_back(std::thread{fn, i})
|		|		|		|		|		|-->Task_queue::execute() //Task_queue::mt_execute 任务调度器
|		|		|		|		|		|		|-->task=m_tasks.front()//进任务队列先加mutex，然后取任务
|		|		|		|		|		|		|-->task() 			//Loader::Task::operator() 进入状态机
|		|		|		|		|		|		|		|-->i. Builder::setup_sort() //State::SETUP_SORT状态 
|		|		|		|		|		|		|		|		|-->create_merge_sort_tasks()
|		|		|		|		|		|		|		|		|		|-->n_runs_to_merge+=thread_ctx->m_offsets.size()//统计所有临时文件大小给pfs 
|		|		|		|		|		|		|		|		|		|-->set_next_state() //State::SETUP_SORT ==> State::SORT
|		|		|		|		|		|		|		|		|		|-->m_loader.add_task() //task与thread_ctx对应，跟并行扫描线程数对应
|		|		|		|		|		|		|		|-->ii.Builder::merge_sort() //State::SORT状态。对每一个临时文件进行merge_sort
|		|		|		|		|		|		|		|		|-->Merge_file_sort::sort()//对临时文件进行排序
|		|		|		|		|		|		|		|		|		|-->tmpfd=ddl::file_create_low() //创建一个临时文件作为outfile
|		|		|		|		|		|		|		|		|		|-->merge_ranges()//loop
|		|		|		|		|		|		|		|		|-->set_next_state()//等所有sort task完成后,即所有临时文件都sort后,(BTREE_BUILD)
|		|		|		|		|		|		|		|		|-->m_loader.add_task()//添加一个btree-build任务
|		|		|		|		|		|		|		|-->iii. Builder::btree_build()
|		|		|		|		|		|		|		|		|-->Btree_load::build()
|		|		|		|		|		|		|		|		|-->Btree_load::finish()
|		|		|		|		|		|		|		|		|-->set_next_state()//State::BTREE_BUILD ==> State::FINISH
|		|		|		|		|		|		|		|-->iv. Builder::finish()	//清理工作
|		|		|		|		|		|		|		|		|--> //loop, 遍历 m_thread_ctxs
|		|		|		|		|		|		|		|		|-->thread_ctx->m_file.m_file.close()
|		|		|		|		|		|		|		|		|-->//end loop
|		|		|		|		|		|		|		|		|-->case1: observer->flush() // m_old_table != m_new_table, 重建表 修改主键
|		|		|		|		|		|		|		|		|		|-->buf_LRU_flush_or_remove_pages()//刷脏or清理page
|		|		|		|		|		|		|		|		|-->case2: //非重建表，添加非主键索引
|		|		|		|		|		|		|		|		|-->Builder::finalize()
|		|		|		|		|		|		|		|		|		|-->observer->flush()
|		|		|		|		|		|		|		|		|		|-->write_redo()
|		|		|		|		|		|		|		|		|		|-->row_log_apply()			//回放索引上的增量数据
|		|		|		|		|		|		|		|		|-->set_next_state()//State::FINISH ==> State::STOP
|		|		|		|		|-->-----------------//结束sort-builder流程----------------------------------------------
|		|		|		|		|-->ut::delete_(m_taskq) //清理task队列
|		|		|-->2.2 Context::cleanup() //清理
|		|		|		|-->ut::delete_(observer)
|		|		|		|-->Builder::write_redo(index)//重建表刷redo
|		|-->3. clean_up()
|		|		|-->//重建表 回放表级别增量数据
|		|		|-->row_log_table_apply()
```

##### scan:

- builder 与创建index个数对应，每一个builder中有N个thread_ctx对象（n = parallel_thread 线程数）, thread_ctx负责保留多线程上下文以及管理临时数据。

-  scan阶段复用了并行扫描模块，在读取到rec后，会立即调用回掉函数 把rec 内容拷贝到每一个builder中的key_buffer中，key_buffer中会做排序的，是有序的。如果同时添加多个索引，这样只扫描一次数据，拷贝多份数据。

- 如果key_buffer 满了，则会申请临时文件存放数据。临时文件的个数与data 同thread_ctx一一对应，即每一个builder 都会有N个临时文件。
- 如果ddl设计到主键（需要重建表），那么会采用m_single_threaded_mode单线程模式进行扫描。
- 如果是主键重建，那么可以直接进行插入Btree，key_buffer有序且是单线程。

##### Merge:

-  merge & build都是在load阶段干活的，是由另一线程组来并行工作的，innodb_ddl_threads参数决定worker线程数。

- 整个过程都是task_queue 以及状态机来控制。当并行扫描完成后，会得到4个局部有序的临时文件（如果innodb_parallel_read_threads=4），然后用户线程会再创建3个worker线程（如果innodb_ddl_threads=4），一共有4个线程执行task_queue中任务。

- 可以发现并行排序的任务数量由临时文件数量决定，而临时文件数量由并行扫描线程数决定，前文假设 innodb_parallel_read_threads 为4，这里即使设置innodb_ddl_threads为6，那么也只有4个任务，实际执行的DDL排序线程数量也为4。若设置innodb_ddl_threads为3，那么会有1个DDL线程处理两个临时文件。所以使用上建议设置innodb_parallel_read_threads 、innodb_ddl_threads两者为同一个值。

- DDL线程文件排序过程使用归并排序算法，会创建一个新的临时文件辅助排序。假设临时文件1包含4个有序list，那么第一轮归并排序后得到包含两个有序的list的文件，两轮归并排序后便可以得到一个全局有序的临时文件：

  ```c++
  
  /*Note: key_buffer size =3 innodb_parallel_read_threads=4
  file1,2,3,4:
  ----------------------------------------------------
    1  5  7 ｜ 2  6  10 ｜ 3  20  40  ｜ 4   9   17
  ----------------------------------------------------
                      ｜  |  第一轮归并
                       \ /
                       
  辅助临时文件：
  ----------------------------------------------------
    1  2  5  7  7  10 ｜ 3  4  9  17  20  40
  ----------------------------------------------------
  										｜  |  第二轮归并
                       \ /
   ----------------------------------------------------
    1  2  3  4  5  6  7  9  10  17  20  40
  ----------------------------------------------------*/                    
                       
  ```

  所有并行排序任务结束后，会得到4个有序的临时文件，不会再将这4个个文件归并排序为一个文件

##### Build

- 将4个临时文件构造成一个优先队列，只添加一个构建任务，设置任务状态为Builder::State::BTREE_BUILD。然后会由一个work线程执行该构建任务，会从优先队列中按序取出记录，逐行写入B+树，完成构建过程。设计到btree树的插入，以后可再索引专题分享。

```c++
|-->Builder::btree_build()
|		|-->Btree_load::build()
|		|		|-->//loop fetch数据
|		|		|-->1. Merge_cursor::fetch()
|		|		|		|-->m_pq.top() && m_pq.pop()  //优先队取出当前最小个file_cursor
|		|		|		|-->File_cursor::fetch() //从file中取出数据
|		|		|-->2. Btree_load::insert() 
|		|		|-->3. Merge_cursor::next()
|		|		|		|-->File_cursor::next() //当前file_cursor 移到下一个数据快
|		|		|		|-->m_pq.push(m_cursor) //再push到队列
|		|		|-->//end loop 
```



#### 增量数据回放

rowlog 格式如下：

```c++
/* |<--extra header--->|<-----------实际记录--------------->｜
 * ---------------------------------------------------------
 * | opt_type | old_pk | record data	| virtual data
 * ----------------------------------------------------------- 
 *  opt_type: 1个字节, 记录row log的操作类型。也即ROW_T_INSERT、ROW_T_UPDATE、ROW_T_DELETE
 *  old_pk: 变长大小， 对于update场景，记录old_pk信息(old_pk size + old_pk field)
 *  record data: rec_size + rec_data
 *  virtual data: size + data
 *
 *  insert 类型: opt_type = 65,old_pk无, record data 有；对应函数：row_log_table_low()
 *  update 类型: opt_type = 66,old_pk有, record data 有；对应函数：row_log_table_low()
 *  delete 类型: opt_type = 67,old_pk有, record data 无；对应函数：row_log_table_delete()
 *-------------------------------------------------------------------------------------------------------
 *-------------------------------------------------------------------------------------------------------
 * 二级索引的row_log
 * ----------------------------------------------------------
 * | opt_type | trx_id | record data	
 * | 1 Byte   | 6 Byte |		
 * ----------------------------------------------------------- 
 *  insert 类型: opt_type = 97 
 *  update 类型: opt_type = 98
 *  写入函数：row_log_online_op()
 */
```



##### row_log_apply  && row_log_table_apply

```c++
struct row_log_t {
  ...
  dict_table_t *table;		//重建新表，如果是二级索引，那么为null
  row_log_buf_t tail;		//写的block位置
  row_log_buf_t head;  //读的block位置
 ...
};
```



```c++
|-->row_log_apply() //二级索引回放
|		|-->rw_lock_x_lock(index) //二级索引加X锁
|		|-->row_log_apply_ops()
|		|		|--> //如果读写不是同一block
|		|		|-->1. rw_lock_x_unlock(dict_index_get_lock(index));//立马释放X锁
|		|		|-->2. row_log_block_allocate()//分配buffer
|		|		|-->3. row_log_apply_op()
|		|		|		|-->trx_id = mach_read_from_6()//insert时读取trx id，delete trx_id = 0
|		|		|		|-->row_rec_to_index_entry_low()//读取rec 内容并 转换成dtuple
|		|		|		|-->row_log_apply_op_low()//新的索引上apply
|		|		|		|		|--> mtr_start(&mtr);//开启事物
|		|		|		|		|--> btr_cur_search_to_nth_level() //去搜索这条记录
|		|		|		|		|--> case 1 found:
|		|		|		|		|		|-->case 1.1 ROW_OP_DELETE
|		|		|		|		|		|-->btr_cur_optimistic_delete() //乐观删除
|		|		|		|		|		|-->btr_cur_pessimistic_delete() //失败后，再悲观删除，如果没加锁，会加X锁
|		|		|		|		|		|-->case 1.2 ROW_OP_INSERT //不做操作
|		|		|		|		|--> case 2 not found:
|		|		|		|		|		|-->case 2.1 ROW_OP_DELETE //不做操作
|		|		|		|		|		|-->case 1.2 ROW_OP_INSERT
|		|		|		|		|		|-->btr_cur_optimistic_insert()||btr_cur_pessimistic_insert() //乐观悲观插  
|		|		|-->4. rw_lock_x_lock() //先加锁取下一个block，再循环 
|		|-->dict_index_set_online_status(ONLINE_INDEX_COMPLETE) //标记索引建立完成，可以访问
|		|-->rw_lock_x_unlock(index)//最后一次读写指向是同一block，此时一定是x锁了，所以最后需要释放
```

- Row_log 会记录在/tmp/Innodb Merge Temp File 临时文件中，大小受参数nnodb_online_alter_log_max_size(默认128MB)限制。如果改参数不够大，则会ddl失败。

- row_log 的应用和 row_log 的写入类似，都是以 block （row_log_buf_t）为粒度。

- 整个过程并不会对index全程加锁，在内部row_log 维护了两个指针，head 和 tail，写的时候推进 tail 指针，读的时候推进 head 指针，只有当 head 和 tail 重合的时候（读写同一个 block）时才会一直持有 X 锁，否则会释放掉 X 锁，然后处理完 head 对应的 block 后再次拿 X 锁

- 在row_log_table_apply()应用结束后，会释放掉老表主键上的 X 锁，此时表上的 MDL 锁还是 MDL_SHARED_UPGRADABLE 锁，所有还会再次写入 row_log，这部分的数据会在 DDL 的 commit 阶段再次应用。

  

### Commit  阶段

commit 阶段的主要操作都是在 row_mysql_lock_data_dictionary 保护下进行，主要包括：

1. 再次应用 row_log（row_log_table_apply），在前面已经应用过一次，但是由于没有在 MDL_EXCLUSIVE 的保护下，并且应用完之后又释放了老表主键上的 X 锁，所以可能还会写入新的 row_log rec，这里再做一次应用，应用完之后会释放 row_log 的内存。能不能取消掉前面的一次应用？
2. 重命名老表和新表（dict_table_rename_in_cache），IBD 文件重命名，dict_table_t 对应的 HASH 结构也需要调整；
3. 删除老表（row_drop_table_for_mysql），准确的说是删除 InnoDB 中的老表（dict_table_t 对象和 IBD 文件，实际的文件删除会延后到 post_ddl 中，这里只是记录了 DDL log）；



```c++
|-->ha_innobase::commit_inplace_alter_table() //此时mdl锁已经升级成X锁
|		|-->ha_innobase::commit_inplace_alter_table_impl()
|		|		|-->1. ddl::lock_table(m_prebuilt->trx, ctx->old_table, LOCK_X)//old_table上X锁
|		|		|-->2. dict_mem_create_temporary_tablename()//生成临时表名
|		|		|-->3. dd::acquire_exclusive_table_mdl() //临时表上X mdl锁
|		|		|-->4. row_mysql_lock_data_dictionary() //锁数据字典上操作 dict_operation_lock
|		|		|-->5. dict_stats_stop_bg()				//停止新表，旧表的统计搜集
|		|		|-->6. commit_get_autoinc()				//获取ctx->max_autoinc值
|		|		|-->7. commit_try_rebuild()				//重建表需要再次apply row_log
|		|		|		|-->row_log_table_apply()		//再次应用row_log
|		|		|		|-->Log_DDL::insert_drop_log()//ddl log写入innodb_ddl_log 系统表中
|		|		|-->8. innobase_online_rebuild_log_free() //重建表，old table，释放row_log、
|		|		|-->9. innobase_copy_frm_flags_from_table_share() //设置新表的统计信息以及flags
|		|		|-->10. commit_cache_rebuild()
|		|		|		|-->dict_table_rename_in_cache() // old_table -> tmp_name
|   |   |   |   |--> log_ddl->write_rename_table_log()  // Log_Type::RENAME_TABLE_LOG
|   |   |   |-->dict_table_rename_in_cache()  // new_table -> old_name  
|		|		|		|-->ddl::drop_table(trx, ctx->old_table); //删除old_table
|		|-->is_instant() //是否是instant操作
|		|		|-->Instant_ddl_impl<Table>::commit_instant_ddl()//略....

```













# 三：番外篇

## 内存管理

每个thread 都有一个成员变量` Heaps m_heaps` 来进行内存管理管理，其中Heaps是一个vector

`using Heaps = std::vector<mem_heap_t *, ut::allocator<mem_heap_t *>>;`

初始化：`m_heaps.push_back(mem_heap_create(1024, UT_LOCATION_HERE));`

```c++
static inline mem_heap_t *mem_heap_create(ulint size,
                                          ut::Location loc [[maybe_unused]],
                                          ulint type) {
  mem_block_t *block;

  if (!size) {
    size = MEM_BLOCK_START_SIZE;
  }
	//创建block，从buffer_pool中获取内存
  block = mem_heap_create_block(nullptr, size,
                                IF_DEBUG(loc.filename, loc.line, ) type);

  if (block == nullptr) {
    return (nullptr);
  }

  UT_LIST_INIT(block->base);

  //创建的block加入到block-list首位置
  UT_LIST_ADD_FIRST(block->base, block);

  return (block);
}

mem_block_t *mem_heap_create_block(mem_heap_t *heap, ulint n,
                                   IF_DEBUG(const char *file_name, ulint line, )
                                       ulint type) {
#ifndef UNIV_LIBRARY
  buf_block_t *buf_block = nullptr;
#endif /* !UNIV_LIBRARY */
  mem_block_t *block;
  ulint len;

  ut_ad((type == MEM_HEAP_DYNAMIC) || (type == MEM_HEAP_BUFFER) ||
        (type == MEM_HEAP_BUFFER + MEM_HEAP_BTR_SEARCH));

  if (heap != nullptr) {
    mem_block_validate(heap);
    ut_d(mem_heap_validate(heap));
  }

  /*block header + data. */
  len = MEM_BLOCK_HEADER_SIZE + MEM_SPACE_NEEDED(n);

#if !defined(UNIV_LIBRARY) && !defined(UNIV_HOTBACKUP)
  if (type == MEM_HEAP_DYNAMIC || len < UNIV_PAGE_SIZE / 2) {
    ut_ad(type == MEM_HEAP_DYNAMIC || n <= MEM_MAX_ALLOC_IN_BUF);

    block = static_cast<mem_block_t *>(
        ut::malloc_withkey(UT_NEW_THIS_FILE_PSI_KEY, len));
  } else {
    len = UNIV_PAGE_SIZE;

    if ((type & MEM_HEAP_BTR_SEARCH) && heap) {
      //从heap中free_list中获取内存,上层调用函数 mem_heap_add_block()
      ut_ad(heap->free_block_ptr != nullptr);
      buf_block = static_cast<buf_block_t *>(heap->free_block_ptr->load());

      if (!buf_block) {
        return nullptr;
      }
      heap->free_block_ptr->store(nullptr);
    } else {
      //从buffer_pool中获取内存
      buf_block = buf_block_alloc(nullptr);
    }

    block = (mem_block_t *)buf_block->frame;
  }

  if (block == nullptr) {
#ifdef UNIV_NO_ERR_MSGS
    ib::fatal(UT_LOCATION_HERE)
#else
    ib::fatal(UT_LOCATION_HERE, ER_IB_MSG_1274)
#endif /* !UNIV_NO_ERR_MSGS */
        << "Unable to allocate memory of size " << len << ".";
  }

  /* Make only the header part of the block accessible. If it is a block
  from the buffer pool, the len will be UNIV_PAGE_SIZE already. */
  UNIV_MEM_FREE(block, len);
  UNIV_MEM_ALLOC(block, MEM_BLOCK_HEADER_SIZE);

  block->buf_block = buf_block;
  block->free_block_ptr = nullptr;

#else  /* !UNIV_LIBRARY && !UNIV_HOTBACKUP */
  len = MEM_BLOCK_HEADER_SIZE + MEM_SPACE_NEEDED(n);
  block = static_cast<mem_block_t *>(
      ut::malloc_withkey(UT_NEW_THIS_FILE_PSI_KEY, len));
  ut_a(block);
  block->free_block_ptr = nullptr;
#endif /* !UNIV_LIBRARY && !UNIV_HOTBACKUP */

  ut_d(ut_strlcpy_rev(block->file_name, file_name, sizeof(block->file_name)));
  ut_d(block->line = line);

  block->magic_n = MEM_BLOCK_MAGIC_N;
  mem_block_set_len(block, len);
  mem_block_set_type(block, type);
  mem_block_set_start(block, MEM_BLOCK_HEADER_SIZE);
  mem_block_set_free(block, MEM_BLOCK_HEADER_SIZE);

  if (UNIV_UNLIKELY(heap == nullptr)) {
    /* This is the first block of the heap. The field
    total_size should be initialized here */
    block->total_size = len;
  } else {
    /* Not the first allocation for the heap. This block's
    total_length field should be set to undefined and never
    actually used. */
    ut_d(block->total_size = ULINT_UNDEFINED);
    UNIV_MEM_FREE(&block->total_size, sizeof block->total_size);

    heap->total_size += len;
  }

  ut_ad((ulint)MEM_BLOCK_HEADER_SIZE < len);

  return (block);
}
```



清理 ` cleanup(m_heaps, err);`

```c++
auto cleanup = [](Heaps &heaps, dberr_t err) {
    for (auto heap : heaps) {
      if (heap != nullptr) {
        mem_heap_free(heap);
      }
    }
    heaps.clear();
    return err == DB_END_OF_INDEX ? DB_SUCCESS : err;
  };

static inline void mem_heap_free(mem_heap_t *heap) {
  mem_block_t *block;
  mem_block_t *prev_block;

  ut_d(mem_block_validate(heap));

  block = UT_LIST_GET_LAST(heap->base);

#ifndef UNIV_HOTBACKUP
#ifndef UNIV_LIBRARY
  mem_heap_free_block_free(heap);
#endif /* !UNIV_LIBRARY */
#endif /* !UNIV_HOTBACKUP */

  while (block != nullptr) {
    //遍历block-list，依次进行free block
    prev_block = UT_LIST_GET_PREV(list, block);

    mem_heap_block_free(heap, block);

    block = prev_block;
  }
}

void mem_heap_block_free(mem_heap_t *heap,   /*!< in: heap */
                         mem_block_t *block) /*!< in: block to free */
{
#ifndef UNIV_LIBRARY
  buf_block_t *buf_block;

  buf_block = static_cast<buf_block_t *>(block->buf_block);
#endif /* !UNIV_LIBRARY */

  mem_block_validate(block);

  UT_LIST_REMOVE(heap->base, block);

  ut_ad(heap->total_size >= block->len);
  heap->total_size -= block->len;

#ifndef UNIV_LIBRARY
  ulint type = heap->type;
  ulint len = block->len;
#endif /* !UNIV_LIBRARY */

  block->magic_n = MEM_FREED_BLOCK_MAGIC_N;

#ifdef UNIV_DEBUG
  if (mem_block_get_start(block) != mem_block_get_free(block)) {
    validate_no_mans_land((byte *)block + mem_block_get_start(block),
                          MEM_NO_MANS_LAND_BEFORE_BYTE);
    validate_no_mans_land(
        (byte *)block + mem_block_get_free(block) - MEM_NO_MANS_LAND,
        MEM_NO_MANS_LAND_AFTER_BYTE);
  }
#endif

#if !defined(UNIV_LIBRARY) && !defined(UNIV_HOTBACKUP)
  if (type == MEM_HEAP_DYNAMIC || len < UNIV_PAGE_SIZE / 2) {
    ut_ad(!buf_block);
    ut::free(block);
  } else {
    ut_ad(type & MEM_HEAP_BUFFER);

    //调用buffer-pool的接口进行free
    UNIV_MEM_ALLOC(block, UNIV_PAGE_SIZE);
    buf_block_free(buf_block);
  }
#else  /* !UNIV_LIBRARY && !UNIV_HOTBACKUP */
  ut::free(block);
#endif /* !UNIV_LIBRARY && !UNIV_HOTBACKUP */
}
```

## 多线程篇

mysql 常用的是`os_thread_create()` 来创建带任务的函数

```c++
//parallel scan
m_parallel_read_threads.emplace_back(
          os_thread_create(parallel_read_thread_key, i + 1,
                           &Parallel_reader::worker, this, m_thread_ctxs[i]));

/////////////////////////////////////////
template <typename F, typename... Args>
IB_thread create_detached_thread(mysql_pfs_key_t pfs_key,
                                 PSI_thread_seqnum pfs_seqnum, F &&f,
                                 Args &&... args) {
  Detached_thread detached_thread{pfs_key, pfs_seqnum};
  auto thread = detached_thread.thread();

  std::thread t(std::move(detached_thread), f, args...);//调用stl thread创建线程,并执行任务
  t.detach();								//异步执行

  /* Thread t is doing busy waiting until the state is changed
  from NOT_STARTED to ALLOWED_TO_START. That will happen when
  thread.start() will be called. */
  ut_a(thread.state() == IB_thread::State::NOT_STARTED);

  return thread;
}
```

而在此处需要等待子线程完成后再继续主线程逻辑（因为计算结果依赖子线程），采用的非detached模式

```c++
dberr_t Loader::load() noexcept {
  ...
  std::vector<std::thread> threads{};

  if (!sync) {
    auto fn = [=](PSI_thread_seqnum seqnum) -> dberr_t {
#ifdef UNIV_PFS_THREAD
      Runnable runnable{ddl_thread_key, seqnum};
#else
      Runnable runnable{PSI_NOT_INSTRUMENTED, seqnum};
#endif /* UNIV_PFS_THREAD */

      current_thd = nullptr;

      const auto err = runnable(&Task_queue::execute, m_taskq);	//子线程执行任务

      if (err != DB_SUCCESS) {
        m_taskq->signal();
      }

      return err;
    };

    for (size_t i = 1; i < m_ctx.m_max_threads; ++i) {
      try {
        threads.push_back(std::thread{fn, i});.//创建n-1个子线程执行任务
      } catch (...) {
        ib::warn(ER_DDL_MSG_1);
        m_taskq->thread_create_failed();
        break;
      }
    }
  }

  auto err = m_taskq->execute();		//主线程也参与执行任务

  if (!sync) {
    if (err != DB_SUCCESS) {
      m_taskq->signal();
    }

    for (auto &thread : threads) {
      thread.join();					//等待子线程执行完成
    }
  }
}

////线程资源管理 && pfs监控
/** Execute in the context of a non detached MySQL thread. */
class Runnable : public MySQL_thread {
 public:
  /** Constructor for the Runnable object.
  @param[in]    pfs_key         Performance schema key
  @param[in]    pfs_seqnum      Performance schema sequence number */
  explicit Runnable(mysql_pfs_key_t pfs_key, PSI_thread_seqnum pfs_seqnum)
      : MySQL_thread(pfs_key, pfs_seqnum) {}

  /** Method to execute the callable
  @param[in]    f               Callable object
  @param[in]    args            Variable number of args to F
  @retval f return value. */
  template <typename F, typename... Args>
  dberr_t operator()(F &&f, Args &&... args) {
    MySQL_thread::preamble();

    auto task = std::bind(std::forward<F>(f), std::forward<Args>(args)...);

    auto r = task();									//执行任务

    MySQL_thread::epilogue();

    return r;
  }
};
```
