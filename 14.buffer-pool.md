



<img src="/Users/yangjinyin/Library/Application Support/typora-user-images/image-20250904190125098.png" alt="image-20250904190125098" style="zoom:50%;" />

![image-20250904190213769](/Users/yangjinyin/Library/Application Support/typora-user-images/image-20250904190213769.png)



```c++
struct buf_pool_t {
    ...
    ulint                           instance_no;       // 缓冲池实例编号
    ulint                           curr_pool_size;    // 缓冲池实例大小
    buf_chunk_t                     *chunks;           // 缓冲池实例的物理块列表
    hash_table_t                    *page_hash;        // 页哈希表
    hash_table_t                    *zip_hash;         // 伙伴系统分配frame对应的block哈希表
    UT_LIST_BASE_NODE_T(buf_page_t) free;              // 空闲链表
    UT_LIST_BASE_NODE_T(buf_page_t) LRU;               // LRU 链表
    UT_LIST_BASE_NODE_T(buf_page_t) flush_list;        // flush 链表
    UT_LIST_BASE_NODE_T(buf_buddy_free_t) zip_free[BUF_BUDDY_SIZES_MAX]; //伙伴分配系统空闲链表
    BufListMutex                    free_list_mutex;   // 空闲链表的互斥锁
    BufListMutex                    LRU_list_mutex;    // LRU 链表的互斥锁
    BufListMutex                    flush_state_mutex; // flush 链表的互斥锁
    BufListMutex          zip_free_mutex;              // 伙伴分配互斥锁
    BufListMutex          zip_hash_mutex;
    BufListMutex          chunks_mutex;                // chunk mutex链表
    ...
}
```

Buffer Pool中的chunk的大小可以自定义设置，默认是128M。

1. page_hash: 用于加速buffer pool中的page查找, hash key = hash(page_id), page_id = (space_id, page_no), hash value 为buf_page_t
2. flush list: 包含了所有的脏页，数据页控制体记录了最新的lsn和最早修改的lsn
3. free list：block初始化后加入的free链表
4. LRU list：包含所有读入的数据页
5. zip_free： 该结构是由 5 个链表构成的二维数组，分别是 1K、2K、4K、8K 和 16K 的碎片链表，存储从磁盘读入的压缩页，引擎使用伙伴系统来管理该结构。

<img src="/Users/yangjinyin/Library/Application Support/typora-user-images/image-20250904190817983.png" alt="image-20250904190817983" style="zoom:50%;" />





**通过 Buffer Pool 读数据页**

```c++
btr_cur_search_to_nth_level()
->buf_page_get_gen()
|--> fetch.single_page // 读取BP中的page,不在其中则调用IO读取
|    |--> get(block)
|    |    |--> lookup  // 在Hash Map中查找Page
|    |    |    |--> buf_page_hash_get_low // 检查 page_hash 中是否存在
|    |    |--> buf_block_fix // buf_fix_count 计数 +1
|    |    |
|    |    |--> read_page // 从磁盘中读入page至BP
|    |    |    |--> buf_read_page // 从文件中读取 page
|    |    |    |    |--> buf_read_page_low // 分配一个新的Block
|    |    |    |    |    |--> buf_page_init_for_read   // 申请一个新的block,从磁盘中读取Page,装载该Block
|    |    |    |    |    |    |--> buf_LRU_get_free_block // 申请 1 个 block
|    |    |    |    |    |    |--> buf_page_hash_get_low // 再次检查 page_hash 中是否存在
|    |    |    |    |    |    |--> buf_page_init
|    |    |    |    |    |    |    |--> buf_block_init_low
|    |    |    |    |    |    |    |--> buf_page_init_low
|    |    |    |    |    |    |    |--> HASH_INSERT // 插入 page_hash
|    |    |    |    |    |    |--> buf_page_set_io_fix // io_fix 设置为 BUF_IO_READ
|    |    |    |    |    |    |--> buf_LRU_add_block // 添加到 LRU
|    |    |    |    |    |
|    |    |    |    |    |--> _fil_io // 完成io操作读取Page
|    |    |    |    |    |--> buf_page_io_complete // 同步模式 IO 完成,    设置状态
|    |    |    |    |    |    |--> buf_page_set_io_fix // io_fix 设置为 BUF_IO_NONE
|    |
|    |--> buf_page_make_young_if_needed // 是否把该page移入至young区域,在young区域的前1/4时,不移动
|    |
|    |--> buf_read_ahead_linear // 线性预读，见innodb_read_ahead_threshold参数
```

**通过Buffer Pool 刷脏**

刷脏是由page cleaner线程来做的

如果打开 double write 的话，Buffer Pool 刷脏有一个约束，一定要保证数据页已在 double write 中持久化，再将数据页持久化。

double write 为 2 MB（double write 的写都是批量的、顺序的）。这里的行为是：

1. 使用同步 IO（fil_io 参数 sync = true）将脏页写到系统表空间中的 double write 区域
2. 使用异步 IO（fil_io 参数 sync = false）将脏页写到用户表空间中



```c++
|-->buf_flush_page_coordinator_thread()
...
|		|-->buf_flush_page() 
|		|		|-->buf_page_set_io_fix(bpage, BUF_IO_WRITE)//设置 IO 状态为 BUF_IO_WRITE
|		|		|-->buf_flush_write_block_low() //将 Buffer Pool 中的一个脏页持久化（写回磁盘）
|		|		|		|-->log_sys->flushed_to_disk_lsn.load() < bpage->get_newest_lsn() //确保newest_lsn已经持久化
|		|		|		|-->dblwr::write() //写入双写缓冲区并同步到磁盘
```





**buf_block_t 和 buf_page_t**

在 InnoDB 中有两个 page descriptor，分别是 buf_block_t 和 buf_page_t.

buffer chunk 管理一片连续的内存，把内存分为两个部分：buffer pool header / memory buffer。memory buffer 被分割成一个个 page，包括普通页和压缩页，buffer pool header 中保存的是 page descripter（struct buf_block_t），每一个 page descripter 都会指向（buf_block_t::frame）一个 16KB 大小的内存，保存着数据页的真实内容.

```c++
struct buf_block_t {
  buf_page_t page; //page的基本信息                    
  byte *frame;    //指向 16KB 的内存区域，那存放着数据页的真实内容

  ......
}

class buf_page_t {
  page_id_t id;							//page的id
  page_size_t size;					//page的大小

  copyable_atomic_t<buf_io_fix> io_fix;//该页的 IO 状态，用于读写并发控制
  lsn_t oldest_modification;					//不为0，则是脏页
  lsn_t newest_modification					//最近修改该页 redo log record 的 end LSN（或者是 mtr end LSN）
}
  
```





